{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0724abc9-40c9-4add-b063-b6458e76d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def categorize_tag(tag):\n",
    "    \"\"\"Categorizes a tag string based on regex patterns.\"\"\"\n",
    "    if pd.isna(tag):\n",
    "        return 'unknown'\n",
    "    tag_str = str(tag).lower().strip()\n",
    "    if re.match(r'^\\d{2}-[a-z]{3}-\\d{2}-(99acres|magicbricks|olx|housing)', tag_str):\n",
    "        return 'date_source_combo'\n",
    "    if re.match(r'^\\d{2}-\\d{2}-\\d{4}$', tag_str):\n",
    "        return 'date_only'\n",
    "    if tag_str in ['sell-leads', 'cleardeals-lead', 'lead', 'recalling']:\n",
    "        return 'generic_status'\n",
    "    if re.search(r'\\d', tag_str) and re.search(r'[a-zA-Z]', tag_str) and '-' in tag_str:\n",
    "        return 'property_identifier'\n",
    "    return 'other'\n",
    "\n",
    "def create_property_ranking(df_property_leads, all_expired_tags):\n",
    "    \"\"\"\n",
    "    Performs feature engineering to create a sophisticated ranking score for properties.\n",
    "    \"\"\"\n",
    "    print(\"\\nüìà Engineering features for property ranking...\")\n",
    "    \n",
    "    # Group by property tag to calculate features for each property\n",
    "    grouped = df_property_leads.groupby('Tags')\n",
    "    \n",
    "    features = []\n",
    "    for tag, group in grouped:\n",
    "        # We only care about expired properties for the ranking\n",
    "        if tag not in all_expired_tags:\n",
    "            continue\n",
    "            \n",
    "        # 1. High-Value Action Counts\n",
    "        site_visit_done_count = (group['To Lead Type'] == 'Site visit done').sum()\n",
    "        site_visit_scheduled_count = (group['To Lead Type'] == 'Site visit scheduled').sum()\n",
    "        \n",
    "        # 2. Lead Quality (Conversion Rate)\n",
    "        if site_visit_scheduled_count > 0:\n",
    "            schedule_to_done_conversion = site_visit_done_count / site_visit_scheduled_count\n",
    "        else:\n",
    "            schedule_to_done_conversion = 0\n",
    "            \n",
    "        # 3. Engagement Velocity\n",
    "        group = group.sort_values('At')\n",
    "        time_diffs = group['At'].diff().dt.total_seconds() / (3600 * 24) # Difference in days\n",
    "        avg_days_between_interactions = time_diffs.mean()\n",
    "        \n",
    "        features.append({\n",
    "            'Tag': tag,\n",
    "            'total_interactions': len(group),\n",
    "            'site_visit_done_count': site_visit_done_count,\n",
    "            'site_visit_scheduled_count': site_visit_scheduled_count,\n",
    "            'schedule_to_done_conversion': schedule_to_done_conversion,\n",
    "            'avg_days_between_interactions': avg_days_between_interactions\n",
    "        })\n",
    "\n",
    "    if not features:\n",
    "        print(\"‚ö†Ô∏è No expired properties found in the interaction data to rank.\")\n",
    "        return pd.DataFrame(), {}\n",
    "        \n",
    "    ranking_df = pd.DataFrame(features).fillna(0)\n",
    "    \n",
    "    # --- Calculate the final Rank Score ---\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Normalize features so they can be combined in a weighted formula\n",
    "    cols_to_scale = ['total_interactions', 'site_visit_done_count', 'site_visit_scheduled_count', 'schedule_to_done_conversion']\n",
    "    ranking_df[cols_to_scale] = scaler.fit_transform(ranking_df[cols_to_scale])\n",
    "    \n",
    "    # Invert the time difference so that shorter time = higher score\n",
    "    ranking_df['velocity_score'] = 1 - scaler.fit_transform(ranking_df[['avg_days_between_interactions']])\n",
    "    \n",
    "    # Define the weights for each feature. Site visits are most important.\n",
    "    weights = {\n",
    "        'site_visit_done_count': 0.40,\n",
    "        'site_visit_scheduled_count': 0.25,\n",
    "        'schedule_to_done_conversion': 0.15,\n",
    "        'velocity_score': 0.10,\n",
    "        'total_interactions': 0.10\n",
    "    }\n",
    "    \n",
    "    # Calculate the final weighted score\n",
    "    ranking_df['Rank_Score'] = (\n",
    "        ranking_df['site_visit_done_count'] * weights['site_visit_done_count'] +\n",
    "        ranking_df['site_visit_scheduled_count'] * weights['site_visit_scheduled_count'] +\n",
    "        ranking_df['schedule_to_done_conversion'] * weights['schedule_to_done_conversion'] +\n",
    "        ranking_df['velocity_score'] * weights['velocity_score'] +\n",
    "        ranking_df['total_interactions'] * weights['total_interactions']\n",
    "    )\n",
    "    \n",
    "    # Convert the score to an integer weight for the round-robin\n",
    "    ranking_df['Weight'] = (ranking_df['Rank_Score'] * 10).astype(int) + 1 # Min weight of 1\n",
    "    \n",
    "    ranking_df.sort_values(by='Rank_Score', ascending=False, inplace=True)\n",
    "    \n",
    "    print(\"‚úÖ Ranking complete. Top 5 most active/high-quality expired properties:\")\n",
    "    print(ranking_df[['Tag', 'Rank_Score', 'Weight']].head())\n",
    "    \n",
    "    work_scores_dict = ranking_df.set_index('Tag')['Weight'].to_dict()\n",
    "    \n",
    "    return ranking_df, work_scores_dict\n",
    "\n",
    "\n",
    "def route_daily_leads_with_ranking():\n",
    "    \"\"\"\n",
    "    Ranks expired properties with advanced features and routes new leads.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting daily lead routing with advanced property ranking...\")\n",
    "    \n",
    "    try:\n",
    "        with open('matches.json', 'r') as f:\n",
    "            expired_to_active_matches = json.load(f)\n",
    "        df_changes = pd.read_csv('ContactTypeChange.csv', low_memory=False)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error: Missing a required file. {e}\"); return\n",
    "\n",
    "    print(\"\\nüîç Cleaning and filtering lead interaction tags...\")\n",
    "    df_changes['tag_type'] = df_changes['Tags'].apply(categorize_tag)\n",
    "    df_property_leads = df_changes[df_changes['tag_type'] == 'property_identifier'].copy()\n",
    "    df_property_leads['At'] = pd.to_datetime(df_property_leads['At'], errors='coerce')\n",
    "    print(f\"‚úÖ Found {len(df_property_leads)} interactions linked to specific properties.\")\n",
    "\n",
    "    # --- Create the Property Ranking ---\n",
    "    all_expired_tags = list(expired_to_active_matches.keys())\n",
    "    ranking_df, work_scores_dict = create_property_ranking(df_property_leads, all_expired_tags)\n",
    "    \n",
    "    if ranking_df.empty: return\n",
    "\n",
    "    # --- Prepare for Routing ---\n",
    "    most_recent_date = df_property_leads['At'].max().date()\n",
    "    daily_leads = df_property_leads[df_property_leads['At'].dt.date == most_recent_date]\n",
    "    print(f\"\\nüóìÔ∏è Simulating daily run for date: {most_recent_date}\")\n",
    "\n",
    "    active_to_expired_map = defaultdict(list)\n",
    "    for expired_tag, active_tags in expired_to_active_matches.items():\n",
    "        for active_tag in active_tags:\n",
    "            active_to_expired_map[active_tag].append(expired_tag)\n",
    "\n",
    "    # --- Weighted Round-Robin Routing based on Rank ---\n",
    "    routed_leads = []\n",
    "    last_assigned_index = defaultdict(int)\n",
    "\n",
    "    for _, lead in daily_leads.iterrows():\n",
    "        active_prop_tag = lead['Tags']\n",
    "        \n",
    "        if active_prop_tag in active_to_expired_map:\n",
    "            candidate_expired_props = active_to_expired_map[active_prop_tag]\n",
    "            if not candidate_expired_props: continue\n",
    "\n",
    "            weighted_candidate_list = []\n",
    "            for expired_tag in candidate_expired_props:\n",
    "                score = work_scores_dict.get(expired_tag, 1)\n",
    "                weighted_candidate_list.extend([expired_tag] * score)\n",
    "            \n",
    "            if not weighted_candidate_list: continue\n",
    "\n",
    "            pool_key = active_prop_tag\n",
    "            current_index = last_assigned_index[pool_key]\n",
    "            assigned_expired_tag = weighted_candidate_list[current_index % len(weighted_candidate_list)]\n",
    "            last_assigned_index[pool_key] += 1\n",
    "            \n",
    "            routed_leads.append({\n",
    "                'lead_contact': lead['Contact'],\n",
    "                'original_active_property_tag': active_prop_tag,\n",
    "                'routed_to_expired_property_tag': assigned_expired_tag,\n",
    "                'timestamp': lead['At']\n",
    "            })\n",
    "\n",
    "    # --- Save and Display Results ---\n",
    "    if routed_leads:\n",
    "        routing_results_df = pd.DataFrame(routed_leads)\n",
    "        routing_results_df.to_csv('todays_routed_leads.csv', index=False)\n",
    "        print(f\"\\n‚úÖ Lead routing complete. Routed {len(routed_leads)} new leads.\")\n",
    "        print(\"Results saved to 'todays_routed_leads.csv'.\")\n",
    "        print(\"\\n--- Sample of Routed Leads ---\")\n",
    "        print(routing_results_df.head())\n",
    "    else:\n",
    "        print(\"\\n‚ÑπÔ∏è No new leads were routed today for the matched properties.\")\n",
    "\n",
    "# --- How to run this ---\n",
    "# route_daily_leads_with_ranking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce6f2a04-53d3-49cb-b8af-724d060b7c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting daily lead routing with advanced property ranking...\n",
      "\n",
      "üîç Cleaning and filtering lead interaction tags...\n",
      "‚úÖ Found 74902 interactions linked to specific properties.\n",
      "\n",
      "üìà Engineering features for property ranking...\n",
      "‚úÖ Ranking complete. Top 5 most active/high-quality expired properties:\n",
      "                                             Tag  Rank_Score  Weight\n",
      "522             a-304-vrajdham-1-ghatlodia-jan25    0.768037       8\n",
      "848                c-203-ganesh-gold-gota-sept24    0.672587       7\n",
      "86           155-aarti-apartment-ghatlodia-feb25    0.654443       7\n",
      "466      a-1306-abhishek-heights-naranpura-oct24    0.624352       7\n",
      "89   16-shreenath-society-part-2-ghatlodia-may24    0.621482       7\n",
      "\n",
      "üóìÔ∏è Simulating daily run for date: 2025-07-31\n",
      "\n",
      "‚úÖ Lead routing complete. Routed 235 new leads.\n",
      "Results saved to 'todays_routed_leads.csv'.\n",
      "\n",
      "--- Sample of Routed Leads ---\n",
      "         lead_contact                  original_active_property_tag  \\\n",
      "0  Abdulhannan Shaikh  c-302-signature-2-business-park-sanand-may25   \n",
      "1                Aish      b-22-santa-sagar-tower-navrangpura-may25   \n",
      "2                Aish      b-22-santa-sagar-tower-navrangpura-may25   \n",
      "3            Ajay sir                117-smruti-vihar-isanpur-may25   \n",
      "4         Ajeet Yadav               b-301-maruti-bliss-avenue-jul25   \n",
      "\n",
      "                   routed_to_expired_property_tag           timestamp  \n",
      "0                 1209-capstone-ellisbridge-jun24 2025-07-31 10:29:00  \n",
      "1               102-rajvi-apartment-paldi-march25 2025-07-31 17:58:00  \n",
      "2               102-rajvi-apartment-paldi-march25 2025-07-31 10:40:00  \n",
      "3  3-h-9-balaji-aghora-residency-chandkheda-dec24 2025-07-31 12:25:00  \n",
      "4             1-shitvan-apartment-maninagar-feb25 2025-07-31 11:58:00  \n"
     ]
    }
   ],
   "source": [
    "route_daily_leads_with_ranking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c0f52a4-a0be-4be6-8716-259ac4a65f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def categorize_tag(tag):\n",
    "    \"\"\"Categorizes a tag string based on regex patterns.\"\"\"\n",
    "    if pd.isna(tag):\n",
    "        return 'unknown'\n",
    "    tag_str = str(tag).lower().strip()\n",
    "    if re.match(r'^\\d{2}-[a-z]{3}-\\d{2}-(99acres|magicbricks|olx|housing)', tag_str):\n",
    "        return 'date_source_combo'\n",
    "    if re.match(r'^\\d{2}-\\d{2}-\\d{4}$', tag_str):\n",
    "        return 'date_only'\n",
    "    if tag_str in ['sell-leads', 'cleardeals-lead', 'lead', 'recalling']:\n",
    "        return 'generic_status'\n",
    "    if re.search(r'\\d', tag_str) and re.search(r'[a-zA-Z]', tag_str) and '-' in tag_str:\n",
    "        return 'property_identifier'\n",
    "    return 'other'\n",
    "\n",
    "def analyze_zero_match_rankings(matches_path='matches.json', interactions_path='ContactTypeChange.csv'):\n",
    "    \"\"\"\n",
    "    Analyzes the quality ranking of expired properties that had zero matches.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(matches_path, 'r') as f:\n",
    "            matches_data = json.load(f)\n",
    "        df_changes = pd.read_csv(interactions_path, low_memory=False)\n",
    "        print(\"‚úÖ Successfully loaded required files.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error: A required file was not found. {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 1. Identify the zero-match properties ---\n",
    "    zero_match_tags = {tag for tag, matches in matches_data.items() if len(matches) == 0}\n",
    "    all_expired_tags = list(matches_data.keys())\n",
    "    \n",
    "    print(f\"\\nFound {len(zero_match_tags)} expired properties with 0 matches to analyze.\")\n",
    "\n",
    "    # --- 2. Clean interaction data and create the full ranking ---\n",
    "    df_changes['tag_type'] = df_changes['Tags'].apply(categorize_tag)\n",
    "    df_property_leads = df_changes[df_changes['tag_type'] == 'property_identifier'].copy()\n",
    "    df_property_leads['At'] = pd.to_datetime(df_property_leads['At'], errors='coerce')\n",
    "\n",
    "    # --- Re-create the full ranking DataFrame ---\n",
    "    grouped = df_property_leads.groupby('Tags')\n",
    "    features = []\n",
    "    for tag, group in grouped:\n",
    "        if tag not in all_expired_tags:\n",
    "            continue\n",
    "        \n",
    "        site_visit_done_count = (group['To Lead Type'] == 'Site visit done').sum()\n",
    "        site_visit_scheduled_count = (group['To Lead Type'] == 'Site visit scheduled').sum()\n",
    "        \n",
    "        if site_visit_scheduled_count > 0:\n",
    "            schedule_to_done_conversion = site_visit_done_count / site_visit_scheduled_count\n",
    "        else:\n",
    "            schedule_to_done_conversion = 0\n",
    "            \n",
    "        group = group.sort_values('At')\n",
    "        time_diffs = group['At'].diff().dt.total_seconds() / (3600 * 24)\n",
    "        avg_days_between_interactions = time_diffs.mean()\n",
    "        \n",
    "        features.append({\n",
    "            'Tag': tag,\n",
    "            'total_interactions': len(group),\n",
    "            'site_visit_done_count': site_visit_done_count,\n",
    "            'site_visit_scheduled_count': site_visit_scheduled_count,\n",
    "            'schedule_to_done_conversion': schedule_to_done_conversion,\n",
    "            'avg_days_between_interactions': avg_days_between_interactions\n",
    "        })\n",
    "\n",
    "    if not features:\n",
    "        print(\"‚ö†Ô∏è No expired properties found in the interaction data to rank.\")\n",
    "        return\n",
    "        \n",
    "    ranking_df = pd.DataFrame(features).fillna(0)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    cols_to_scale = ['total_interactions', 'site_visit_done_count', 'site_visit_scheduled_count', 'schedule_to_done_conversion']\n",
    "    ranking_df[cols_to_scale] = scaler.fit_transform(ranking_df[cols_to_scale])\n",
    "    \n",
    "    ranking_df['velocity_score'] = 1 - scaler.fit_transform(ranking_df[['avg_days_between_interactions']])\n",
    "    \n",
    "    weights = {\n",
    "        'site_visit_done_count': 0.40,\n",
    "        'site_visit_scheduled_count': 0.25,\n",
    "        'schedule_to_done_conversion': 0.15,\n",
    "        'velocity_score': 0.10,\n",
    "        'total_interactions': 0.10\n",
    "    }\n",
    "    \n",
    "    ranking_df['Rank_Score'] = (\n",
    "        ranking_df['site_visit_done_count'] * weights['site_visit_done_count'] +\n",
    "        ranking_df['site_visit_scheduled_count'] * weights['site_visit_scheduled_count'] +\n",
    "        ranking_df['schedule_to_done_conversion'] * weights['schedule_to_done_conversion'] +\n",
    "        ranking_df['velocity_score'] * weights['velocity_score'] +\n",
    "        ranking_df['total_interactions'] * weights['total_interactions']\n",
    "    )\n",
    "    \n",
    "    ranking_df.sort_values(by='Rank_Score', ascending=False, inplace=True)\n",
    "    ranking_df.reset_index(inplace=True)\n",
    "    ranking_df.rename(columns={'index': 'Overall_Rank'}, inplace=True)\n",
    "    ranking_df['Overall_Rank'] = ranking_df.index + 1\n",
    "\n",
    "\n",
    "    # --- 3. Filter the ranking to show only the zero-match properties ---\n",
    "    zero_match_ranking_df = ranking_df[ranking_df['Tag'].isin(zero_match_tags)]\n",
    "\n",
    "    print(\"\\n\\n--- üìä Ranking Analysis for Zero-Match Properties ---\")\n",
    "    print(\"This table shows the final rank and quality score for the properties that had no matches.\")\n",
    "    print(zero_match_ranking_df[['Tag', 'Overall_Rank', 'Rank_Score']].head(20))\n",
    "\n",
    "    # --- 4. Analyze the distribution of their ranks ---\n",
    "    print(\"\\n--- üìà Distribution of Ranks ---\")\n",
    "    rank_distribution = pd.cut(\n",
    "        zero_match_ranking_df['Overall_Rank'],\n",
    "        bins=[0, 100, 500, 1000, 1500, 2000],\n",
    "        labels=['Top 100', 'Rank 101-500', 'Rank 501-1000', 'Rank 1001-1500', 'Rank 1501+']\n",
    "    ).value_counts().sort_index()\n",
    "\n",
    "    print(\"This shows where the zero-match properties fall in the overall quality ranking:\")\n",
    "    print(rank_distribution)\n",
    "\n",
    "# --- How to run this in your notebook ---\n",
    "# analyze_zero_match_rankings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3a97825-94e3-47c8-b7ba-545c7ca9c0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded required files.\n",
      "\n",
      "Found 73 expired properties with 0 matches to analyze.\n",
      "\n",
      "\n",
      "--- üìä Ranking Analysis for Zero-Match Properties ---\n",
      "This table shows the final rank and quality score for the properties that had no matches.\n",
      "                                                  Tag  Overall_Rank  \\\n",
      "39                       c-302-suvas-oram-odhav-aug24            40   \n",
      "130                    c-103-aditya-oriana-gota-jan24           131   \n",
      "171                     23-mahavir-villa-mahudi-aug24           172   \n",
      "196                 69-mayur-park-society-nikol-oct24           197   \n",
      "206          3-samta-society-subhashbridge-rent-oct24           207   \n",
      "238              23-24-sabandh-bunglows-thaltej-jun24           239   \n",
      "254                  q-504-paradise-park-vinzol-feb25           255   \n",
      "336                          b-3-ratnadweepflat-vasna           337   \n",
      "366                 25-sharnam-sky-vastral-rent-aug24           367   \n",
      "390      j-201-parshwanath-atlantis-park-sughad-feb25           391   \n",
      "392  m1-401-shree-thakornath-residency-dahegam-sept24           393   \n",
      "394                s-14-oxford-tower-memnagar-march25           395   \n",
      "395               a-9-160-161-royal-woods-bavla-aug24           396   \n",
      "402  m-1-104-shree-thakornath-residency-dahegam-oct24           403   \n",
      "405                b-3-geeta-apartment-ambawadi-feb25           406   \n",
      "464        302-addor-ambitions-navrangpura-aug24-rent           465   \n",
      "490                   m-702-shukan-sky-randasan-aug24           491   \n",
      "501              b-1102-vandematram-fabula-gota-oct24           502   \n",
      "553                          c-20-hub-town-com-sept24           554   \n",
      "568            f-502-platinum-elegance-hathijan-dec24           569   \n",
      "\n",
      "     Rank_Score  \n",
      "39     0.396409  \n",
      "130    0.275091  \n",
      "171    0.242132  \n",
      "196    0.231370  \n",
      "206    0.227601  \n",
      "238    0.213796  \n",
      "254    0.209134  \n",
      "336    0.186357  \n",
      "366    0.180448  \n",
      "390    0.173802  \n",
      "392    0.173705  \n",
      "394    0.172994  \n",
      "395    0.172971  \n",
      "402    0.171806  \n",
      "405    0.171375  \n",
      "464    0.159672  \n",
      "490    0.156656  \n",
      "501    0.155335  \n",
      "553    0.147468  \n",
      "568    0.144951  \n",
      "\n",
      "--- üìà Distribution of Ranks ---\n",
      "This shows where the zero-match properties fall in the overall quality ranking:\n",
      "Overall_Rank\n",
      "Top 100            1\n",
      "Rank 101-500      16\n",
      "Rank 501-1000     25\n",
      "Rank 1001-1500    13\n",
      "Rank 1501+         0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "analyze_zero_match_rankings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac369df9-f64b-48dc-8984-751243c276f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def categorize_tag(tag):\n",
    "    \"\"\"Categorizes a tag string based on regex patterns.\"\"\"\n",
    "    if pd.isna(tag):\n",
    "        return 'unknown'\n",
    "    tag_str = str(tag).lower().strip()\n",
    "    if re.match(r'^\\d{2}-[a-z]{3}-\\d{2}-(99acres|magicbricks|olx|housing)', tag_str):\n",
    "        return 'date_source_combo'\n",
    "    if re.match(r'^\\d{2}-\\d{2}-\\d{4}$', tag_str):\n",
    "        return 'date_only'\n",
    "    if tag_str in ['sell-leads', 'cleardeals-lead', 'lead', 'recalling']:\n",
    "        return 'generic_status'\n",
    "    if re.search(r'\\d', tag_str) and re.search(r'[a-zA-Z]', tag_str) and '-' in tag_str:\n",
    "        return 'property_identifier'\n",
    "    return 'other'\n",
    "\n",
    "def create_property_ranking(df_property_leads, all_expired_tags):\n",
    "    \"\"\"\n",
    "    Performs feature engineering to create a sophisticated ranking score for properties.\n",
    "    \"\"\"\n",
    "    print(\"\\nüìà Engineering features for property ranking...\")\n",
    "    \n",
    "    grouped = df_property_leads.groupby('Tags')\n",
    "    \n",
    "    features = []\n",
    "    for tag, group in grouped:\n",
    "        if tag not in all_expired_tags:\n",
    "            continue\n",
    "            \n",
    "        site_visit_done_count = (group['To Lead Type'] == 'Site visit done').sum()\n",
    "        site_visit_scheduled_count = (group['To Lead Type'] == 'Site visit scheduled').sum()\n",
    "        \n",
    "        if site_visit_scheduled_count > 0:\n",
    "            schedule_to_done_conversion = site_visit_done_count / site_visit_scheduled_count\n",
    "        else:\n",
    "            schedule_to_done_conversion = 0\n",
    "            \n",
    "        group = group.sort_values('At')\n",
    "        time_diffs = group['At'].diff().dt.total_seconds() / (3600 * 24)\n",
    "        avg_days_between_interactions = time_diffs.mean()\n",
    "        \n",
    "        features.append({\n",
    "            'Tag': tag,\n",
    "            'total_interactions': len(group),\n",
    "            'site_visit_done_count': site_visit_done_count,\n",
    "            'site_visit_scheduled_count': site_visit_scheduled_count,\n",
    "            'schedule_to_done_conversion': schedule_to_done_conversion,\n",
    "            'avg_days_between_interactions': avg_days_between_interactions\n",
    "        })\n",
    "\n",
    "    if not features:\n",
    "        print(\"‚ö†Ô∏è No expired properties found in the interaction data to rank.\")\n",
    "        return pd.DataFrame(), {}\n",
    "        \n",
    "    ranking_df = pd.DataFrame(features).fillna(0)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    cols_to_scale = ['total_interactions', 'site_visit_done_count', 'site_visit_scheduled_count', 'schedule_to_done_conversion']\n",
    "    ranking_df[cols_to_scale] = scaler.fit_transform(ranking_df[cols_to_scale])\n",
    "    \n",
    "    ranking_df['velocity_score'] = 1 - scaler.fit_transform(ranking_df[['avg_days_between_interactions']])\n",
    "    \n",
    "    weights = {\n",
    "        'site_visit_done_count': 0.40,\n",
    "        'site_visit_scheduled_count': 0.25,\n",
    "        'schedule_to_done_conversion': 0.15,\n",
    "        'velocity_score': 0.10,\n",
    "        'total_interactions': 0.10\n",
    "    }\n",
    "    \n",
    "    ranking_df['Rank_Score'] = (\n",
    "        ranking_df['site_visit_done_count'] * weights['site_visit_done_count'] +\n",
    "        ranking_df['site_visit_scheduled_count'] * weights['site_visit_scheduled_count'] +\n",
    "        ranking_df['schedule_to_done_conversion'] * weights['schedule_to_done_conversion'] +\n",
    "        ranking_df['velocity_score'] * weights['velocity_score'] +\n",
    "        ranking_df['total_interactions'] * weights['total_interactions']\n",
    "    )\n",
    "    \n",
    "    ranking_df['Weight'] = (ranking_df['Rank_Score'] * 10).astype(int) + 1\n",
    "    \n",
    "    ranking_df.sort_values(by='Rank_Score', ascending=False, inplace=True)\n",
    "    \n",
    "    print(\"‚úÖ Ranking complete. Top 5 most active/high-quality expired properties:\")\n",
    "    print(ranking_df[['Tag', 'Rank_Score', 'Weight']].head())\n",
    "    \n",
    "    work_scores_dict = ranking_df.set_index('Tag')['Weight'].to_dict()\n",
    "    \n",
    "    return ranking_df, work_scores_dict\n",
    "\n",
    "\n",
    "def route_daily_leads_with_ranking():\n",
    "    \"\"\"\n",
    "    Ranks expired properties and routes new leads with deduplication.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting daily lead routing with advanced property ranking...\")\n",
    "    \n",
    "    try:\n",
    "        with open('matches.json', 'r') as f:\n",
    "            expired_to_active_matches = json.load(f)\n",
    "        df_changes = pd.read_csv('ContactTypeChange.csv', low_memory=False)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error: Missing a required file. {e}\"); return\n",
    "\n",
    "    print(\"\\nüîç Cleaning and filtering lead interaction tags...\")\n",
    "    df_changes['tag_type'] = df_changes['Tags'].apply(categorize_tag)\n",
    "    df_property_leads = df_changes[df_changes['tag_type'] == 'property_identifier'].copy()\n",
    "    df_property_leads['At'] = pd.to_datetime(df_property_leads['At'], errors='coerce')\n",
    "    print(f\"‚úÖ Found {len(df_property_leads)} interactions linked to specific properties.\")\n",
    "\n",
    "    all_expired_tags = list(expired_to_active_matches.keys())\n",
    "    ranking_df, work_scores_dict = create_property_ranking(df_property_leads, all_expired_tags)\n",
    "    \n",
    "    if ranking_df.empty: return\n",
    "\n",
    "    most_recent_date = df_property_leads['At'].max().date()\n",
    "    daily_leads = df_property_leads[df_property_leads['At'].dt.date == most_recent_date]\n",
    "    print(f\"\\nüóìÔ∏è Simulating daily run for date: {most_recent_date}\")\n",
    "\n",
    "    active_to_expired_map = defaultdict(list)\n",
    "    for expired_tag, active_tags in expired_to_active_matches.items():\n",
    "        for active_tag in active_tags:\n",
    "            active_to_expired_map[active_tag].append(expired_tag)\n",
    "\n",
    "    # --- UPDATED: Deduplication Logic ---\n",
    "    routed_leads = []\n",
    "    last_assigned_index = defaultdict(int)\n",
    "    # This log will track assignments for this specific run to prevent duplicates\n",
    "    daily_assignments = defaultdict(set) \n",
    "\n",
    "    for _, lead in daily_leads.iterrows():\n",
    "        active_prop_tag = lead['Tags']\n",
    "        lead_contact = lead['Contact']\n",
    "        \n",
    "        if active_prop_tag in active_to_expired_map:\n",
    "            candidate_expired_props = active_to_expired_map[active_prop_tag]\n",
    "            if not candidate_expired_props: continue\n",
    "\n",
    "            weighted_candidate_list = []\n",
    "            for expired_tag in candidate_expired_props:\n",
    "                score = work_scores_dict.get(expired_tag, 1)\n",
    "                weighted_candidate_list.extend([expired_tag] * score)\n",
    "            \n",
    "            if not weighted_candidate_list: continue\n",
    "\n",
    "            pool_key = active_prop_tag\n",
    "            current_index = last_assigned_index[pool_key]\n",
    "            assigned_expired_tag = weighted_candidate_list[current_index % len(weighted_candidate_list)]\n",
    "            last_assigned_index[pool_key] += 1\n",
    "            \n",
    "            # --- Check if this lead has already been sent to this expired property today ---\n",
    "            if lead_contact not in daily_assignments[assigned_expired_tag]:\n",
    "                routed_leads.append({\n",
    "                    'lead_contact': lead_contact,\n",
    "                    'original_active_property_tag': active_prop_tag,\n",
    "                    'routed_to_expired_property_tag': assigned_expired_tag,\n",
    "                    'timestamp': lead['At']\n",
    "                })\n",
    "                # --- Log the assignment to prevent future duplicates in this run ---\n",
    "                daily_assignments[assigned_expired_tag].add(lead_contact)\n",
    "\n",
    "    # --- Save and Display Results ---\n",
    "    if routed_leads:\n",
    "        routing_results_df = pd.DataFrame(routed_leads)\n",
    "        routing_results_df.to_csv('todays_routed_leads.csv', index=False)\n",
    "        print(f\"\\n‚úÖ Lead routing complete. Routed {len(routed_leads)} new, unique leads.\")\n",
    "        print(\"Results saved to 'todays_routed_leads.csv'.\")\n",
    "        print(\"\\n--- Sample of Routed Leads ---\")\n",
    "        print(routing_results_df.head())\n",
    "    else:\n",
    "        print(\"\\n‚ÑπÔ∏è No new leads were routed today for the matched properties.\")\n",
    "\n",
    "# --- How to run this ---\n",
    "# route_daily_leads_with_ranking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c6716ef-8d55-4fe5-8bcd-4b2d94e6ff5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting daily lead routing with advanced property ranking...\n",
      "\n",
      "üîç Cleaning and filtering lead interaction tags...\n",
      "‚úÖ Found 74902 interactions linked to specific properties.\n",
      "\n",
      "üìà Engineering features for property ranking...\n",
      "‚úÖ Ranking complete. Top 5 most active/high-quality expired properties:\n",
      "                                             Tag  Rank_Score  Weight\n",
      "522             a-304-vrajdham-1-ghatlodia-jan25    0.768037       8\n",
      "848                c-203-ganesh-gold-gota-sept24    0.672587       7\n",
      "86           155-aarti-apartment-ghatlodia-feb25    0.654443       7\n",
      "466      a-1306-abhishek-heights-naranpura-oct24    0.624352       7\n",
      "89   16-shreenath-society-part-2-ghatlodia-may24    0.621482       7\n",
      "\n",
      "üóìÔ∏è Simulating daily run for date: 2025-07-31\n",
      "\n",
      "‚úÖ Lead routing complete. Routed 220 new, unique leads.\n",
      "Results saved to 'todays_routed_leads.csv'.\n",
      "\n",
      "--- Sample of Routed Leads ---\n",
      "         lead_contact                  original_active_property_tag  \\\n",
      "0  Abdulhannan Shaikh  c-302-signature-2-business-park-sanand-may25   \n",
      "1                Aish      b-22-santa-sagar-tower-navrangpura-may25   \n",
      "2            Ajay sir                117-smruti-vihar-isanpur-may25   \n",
      "3         Ajeet Yadav               b-301-maruti-bliss-avenue-jul25   \n",
      "4           Akash Jha       b-208-aatrey-elegance-nava-naroda-jun25   \n",
      "\n",
      "                   routed_to_expired_property_tag           timestamp  \n",
      "0                 1209-capstone-ellisbridge-jun24 2025-07-31 10:29:00  \n",
      "1               102-rajvi-apartment-paldi-march25 2025-07-31 17:58:00  \n",
      "2  3-h-9-balaji-aghora-residency-chandkheda-dec24 2025-07-31 12:25:00  \n",
      "3             1-shitvan-apartment-maninagar-feb25 2025-07-31 11:58:00  \n",
      "4              376-1-9-duplex-market-naroda-dec24 2025-07-31 16:36:00  \n"
     ]
    }
   ],
   "source": [
    "route_daily_leads_with_ranking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "523b1292-f903-4261-98d2-b2c1df4d7b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def categorize_tag(tag):\n",
    "    \"\"\"Categorizes a tag string based on regex patterns.\"\"\"\n",
    "    if pd.isna(tag):\n",
    "        return 'unknown'\n",
    "    tag_str = str(tag).lower().strip()\n",
    "    if re.match(r'^\\d{2}-[a-z]{3}-\\d{2}-(99acres|magicbricks|olx|housing)', tag_str):\n",
    "        return 'date_source_combo'\n",
    "    if re.match(r'^\\d{2}-\\d{2}-\\d{4}$', tag_str):\n",
    "        return 'date_only'\n",
    "    if tag_str in ['sell-leads', 'cleardeals-lead', 'lead', 'recalling']:\n",
    "        return 'generic_status'\n",
    "    if re.search(r'\\d', tag_str) and re.search(r'[a-zA-Z]', tag_str) and '-' in tag_str:\n",
    "        return 'property_identifier'\n",
    "    return 'other'\n",
    "\n",
    "def create_property_ranking(df_property_leads, all_expired_tags):\n",
    "    \"\"\"\n",
    "    Performs feature engineering to create a sophisticated ranking score for properties.\n",
    "    \"\"\"\n",
    "    print(\"\\nüìà Engineering features for property ranking...\")\n",
    "    \n",
    "    grouped = df_property_leads.groupby('Tags')\n",
    "    \n",
    "    features = []\n",
    "    for tag, group in grouped:\n",
    "        if tag not in all_expired_tags:\n",
    "            continue\n",
    "            \n",
    "        site_visit_done_count = (group['To Lead Type'] == 'Site visit done').sum()\n",
    "        site_visit_scheduled_count = (group['To Lead Type'] == 'Site visit scheduled').sum()\n",
    "        \n",
    "        if site_visit_scheduled_count > 0:\n",
    "            schedule_to_done_conversion = site_visit_done_count / site_visit_scheduled_count\n",
    "        else:\n",
    "            schedule_to_done_conversion = 0\n",
    "            \n",
    "        group = group.sort_values('At')\n",
    "        time_diffs = group['At'].diff().dt.total_seconds() / (3600 * 24)\n",
    "        avg_days_between_interactions = time_diffs.mean()\n",
    "        \n",
    "        features.append({\n",
    "            'Tag': tag,\n",
    "            'total_interactions': len(group),\n",
    "            'site_visit_done_count': site_visit_done_count,\n",
    "            'site_visit_scheduled_count': site_visit_scheduled_count,\n",
    "            'schedule_to_done_conversion': schedule_to_done_conversion,\n",
    "            'avg_days_between_interactions': avg_days_between_interactions\n",
    "        })\n",
    "\n",
    "    if not features:\n",
    "        print(\"‚ö†Ô∏è No expired properties found in the interaction data to rank.\")\n",
    "        return pd.DataFrame(), {}\n",
    "        \n",
    "    ranking_df = pd.DataFrame(features).fillna(0)\n",
    "    \n",
    "    # Store original features before scaling for the final report\n",
    "    original_features_df = ranking_df.copy()\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    cols_to_scale = ['total_interactions', 'site_visit_done_count', 'site_visit_scheduled_count', 'schedule_to_done_conversion']\n",
    "    ranking_df[cols_to_scale] = scaler.fit_transform(ranking_df[cols_to_scale])\n",
    "    \n",
    "    ranking_df['velocity_score'] = 1 - scaler.fit_transform(ranking_df[['avg_days_between_interactions']])\n",
    "    \n",
    "    weights = {\n",
    "        'site_visit_done_count': 0.40,\n",
    "        'site_visit_scheduled_count': 0.25,\n",
    "        'schedule_to_done_conversion': 0.15,\n",
    "        'velocity_score': 0.10,\n",
    "        'total_interactions': 0.10\n",
    "    }\n",
    "    \n",
    "    ranking_df['Rank_Score'] = (\n",
    "        ranking_df['site_visit_done_count'] * weights['site_visit_done_count'] +\n",
    "        ranking_df['site_visit_scheduled_count'] * weights['site_visit_scheduled_count'] +\n",
    "        ranking_df['schedule_to_done_conversion'] * weights['schedule_to_done_conversion'] +\n",
    "        ranking_df['velocity_score'] * weights['velocity_score'] +\n",
    "        ranking_df['total_interactions'] * weights['total_interactions']\n",
    "    )\n",
    "    \n",
    "    ranking_df['Weight'] = (ranking_df['Rank_Score'] * 10).astype(int) + 1\n",
    "    \n",
    "    # Merge back original features for the final report\n",
    "    final_ranking_df = pd.merge(original_features_df, ranking_df[['Tag', 'Rank_Score', 'Weight']], on='Tag')\n",
    "    final_ranking_df.sort_values(by='Rank_Score', ascending=False, inplace=True)\n",
    "    \n",
    "    # --- THIS IS THE FIX ---\n",
    "    final_ranking_df.reset_index(drop=True, inplace=True)\n",
    "    final_ranking_df['Overall_Rank'] = final_ranking_df.index + 1\n",
    "    \n",
    "    print(\"‚úÖ Ranking complete.\")\n",
    "    \n",
    "    work_scores_dict = final_ranking_df.set_index('Tag')['Weight'].to_dict()\n",
    "    \n",
    "    return final_ranking_df, work_scores_dict\n",
    "\n",
    "    \n",
    "def analyze_daily_routing(ranking_df, routed_leads_df):\n",
    "    \"\"\"\n",
    "    Analyzes and displays the results of the lead routing simulation,\n",
    "    including the overall rank of each property.\n",
    "    \"\"\"\n",
    "    print(\"\\n\\n--- üìä Detailed Lead Routing Analysis ---\")\n",
    "    \n",
    "    if routed_leads_df.empty:\n",
    "        print(\"No leads were routed, so no analysis can be performed.\")\n",
    "        return\n",
    "\n",
    "    # Count how many leads were assigned to each expired property\n",
    "    lead_counts = routed_leads_df['routed_to_expired_property_tag'].value_counts().reset_index()\n",
    "    lead_counts.columns = ['Tag', 'Leads_Received_Today']\n",
    "    \n",
    "    # Merge the lead counts with the original ranking dataframe\n",
    "    # The ranking_df already has the 'Overall_Rank' from the create_property_ranking function\n",
    "    analysis_df = pd.merge(ranking_df, lead_counts, on='Tag', how='left').fillna(0)\n",
    "    analysis_df['Leads_Received_Today'] = analysis_df['Leads_Received_Today'].astype(int)\n",
    "    \n",
    "    # Filter to show only properties that received leads today\n",
    "    analysis_df = analysis_df[analysis_df['Leads_Received_Today'] > 0]\n",
    "    analysis_df.sort_values(by='Leads_Received_Today', ascending=False, inplace=True)\n",
    "    \n",
    "    print(\"The table below shows the ranking features for each expired property and the number of leads it received in today's run.\")\n",
    "    \n",
    "    # UPDATED: Added 'Overall_Rank' to the display columns\n",
    "    display_cols = [\n",
    "        'Tag', 'Overall_Rank', 'Rank_Score', 'Weight', 'Leads_Received_Today',\n",
    "        'total_interactions', 'site_visit_done_count', 'site_visit_scheduled_count',\n",
    "        'schedule_to_done_conversion', 'avg_days_between_interactions'\n",
    "    ]\n",
    "    \n",
    "    print(analysis_df[display_cols].head(20))\n",
    "\n",
    "    # Visualize the distribution\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_20_analysis = analysis_df.head(20)\n",
    "    sns.barplot(x='Leads_Received_Today', y='Tag', data=top_20_analysis, palette='viridis')\n",
    "    plt.title('Number of Leads Routed to Expired Properties (Top 20)')\n",
    "    plt.xlabel('Number of Leads Received')\n",
    "    plt.ylabel('Expired Property Tag')\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "def route_daily_leads_with_ranking():\n",
    "    \"\"\"\n",
    "    Ranks expired properties and routes new leads with deduplication.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting daily lead routing with advanced property ranking...\")\n",
    "    \n",
    "    try:\n",
    "        with open('matches.json', 'r') as f:\n",
    "            expired_to_active_matches = json.load(f)\n",
    "        df_changes = pd.read_csv('ContactTypeChange.csv', low_memory=False)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error: Missing a required file. {e}\"); return\n",
    "\n",
    "    print(\"\\nüîç Cleaning and filtering lead interaction tags...\")\n",
    "    df_changes['tag_type'] = df_changes['Tags'].apply(categorize_tag)\n",
    "    df_property_leads = df_changes[df_changes['tag_type'] == 'property_identifier'].copy()\n",
    "    df_property_leads['At'] = pd.to_datetime(df_property_leads['At'], errors='coerce')\n",
    "    print(f\"‚úÖ Found {len(df_property_leads)} interactions linked to specific properties.\")\n",
    "\n",
    "    all_expired_tags = list(expired_to_active_matches.keys())\n",
    "    ranking_df, work_scores_dict = create_property_ranking(df_property_leads, all_expired_tags)\n",
    "    \n",
    "    if ranking_df.empty: return\n",
    "\n",
    "    most_recent_date = df_property_leads['At'].max().date()\n",
    "    daily_leads = df_property_leads[df_property_leads['At'].dt.date == most_recent_date]\n",
    "    print(f\"\\nüóìÔ∏è Simulating daily run for date: {most_recent_date}\")\n",
    "\n",
    "    active_to_expired_map = defaultdict(list)\n",
    "    for expired_tag, active_tags in expired_to_active_matches.items():\n",
    "        for active_tag in active_tags:\n",
    "            active_to_expired_map[active_tag].append(expired_tag)\n",
    "\n",
    "    routed_leads = []\n",
    "    last_assigned_index = defaultdict(int)\n",
    "    daily_assignments = defaultdict(set) \n",
    "\n",
    "    for _, lead in daily_leads.iterrows():\n",
    "        active_prop_tag = lead['Tags']\n",
    "        lead_contact = lead['Contact']\n",
    "        \n",
    "        if active_prop_tag in active_to_expired_map:\n",
    "            candidate_expired_props = active_to_expired_map[active_prop_tag]\n",
    "            if not candidate_expired_props: continue\n",
    "\n",
    "            weighted_candidate_list = []\n",
    "            for expired_tag in candidate_expired_props:\n",
    "                score = work_scores_dict.get(expired_tag, 1)\n",
    "                weighted_candidate_list.extend([expired_tag] * score)\n",
    "            \n",
    "            if not weighted_candidate_list: continue\n",
    "\n",
    "            pool_key = active_prop_tag\n",
    "            current_index = last_assigned_index[pool_key]\n",
    "            assigned_expired_tag = weighted_candidate_list[current_index % len(weighted_candidate_list)]\n",
    "            last_assigned_index[pool_key] += 1\n",
    "            \n",
    "            if lead_contact not in daily_assignments[assigned_expired_tag]:\n",
    "                routed_leads.append({\n",
    "                    'lead_contact': lead_contact,\n",
    "                    'original_active_property_tag': active_prop_tag,\n",
    "                    'routed_to_expired_property_tag': assigned_expired_tag,\n",
    "                    'timestamp': lead['At']\n",
    "                })\n",
    "                daily_assignments[assigned_expired_tag].add(lead_contact)\n",
    "\n",
    "    if routed_leads:\n",
    "        routing_results_df = pd.DataFrame(routed_leads)\n",
    "        print(f\"\\n‚úÖ Lead routing complete. Routed {len(routed_leads)} new, unique leads.\")\n",
    "        \n",
    "        # --- THIS IS THE KEY CHANGE ---\n",
    "        return ranking_df, routing_results_df\n",
    "    else:\n",
    "        print(\"\\n‚ÑπÔ∏è No new leads were routed today for the matched properties.\")\n",
    "        return pd.DataFrame(), pd.DataFrame() # Return empty dataframes if no leads\n",
    "\n",
    "# --- How to run this ---\n",
    "# route_daily_leads_with_ranking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5066000-88f1-4ffd-a906-98ea477d4406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting daily lead routing with advanced property ranking...\n",
      "\n",
      "üîç Cleaning and filtering lead interaction tags...\n",
      "‚úÖ Found 74902 interactions linked to specific properties.\n",
      "\n",
      "üìà Engineering features for property ranking...\n",
      "‚úÖ Ranking complete.\n",
      "\n",
      "üóìÔ∏è Simulating daily run for date: 2025-07-31\n",
      "\n",
      "‚úÖ Lead routing complete. Routed 225 new, unique leads.\n"
     ]
    }
   ],
   "source": [
    "# This will run the routing and capture the two dataframes you need\n",
    "ranking_df, routing_results_df = route_daily_leads_with_ranking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4b1240a-350e-492e-868b-4d46d1f03b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import HTML\n",
    "\n",
    "def generate_full_lead_report(ranking_df, routed_leads_df):\n",
    "    \"\"\"\n",
    "    Generates a detailed, visually appealing HTML report for all routed leads,\n",
    "    including the rank of each expired property.\n",
    "    \"\"\"\n",
    "    print(\"\\n\\n--- üìÑ Generating Full HTML Lead Report ---\")\n",
    "    \n",
    "    if routed_leads_df.empty:\n",
    "        print(\"No leads were routed, so no report can be generated.\")\n",
    "        return\n",
    "\n",
    "    # Create a dictionary to map Tag to its Overall_Rank for easy lookup\n",
    "    rank_map = ranking_df.set_index('Tag')['Overall_Rank'].to_dict()\n",
    "\n",
    "    # Group leads by the expired property they were routed to\n",
    "    grouped = routed_leads_df.groupby('routed_to_expired_property_tag')\n",
    "\n",
    "    html_parts = []\n",
    "    total_leads_processed = 0\n",
    "\n",
    "    # Sort groups by the number of leads received\n",
    "    sorted_groups = sorted(grouped, key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "    for expired_tag, group_df in sorted_groups:\n",
    "        num_leads = len(group_df)\n",
    "        total_leads_processed += num_leads\n",
    "        \n",
    "        # Get the rank for the current property\n",
    "        rank = rank_map.get(expired_tag, 'N/A')\n",
    "        \n",
    "        # Create a collapsible section for each expired property, now with rank\n",
    "        details_header = f\"\"\"\n",
    "        <details>\n",
    "            <summary>\n",
    "                <strong>Rank #{rank}: {expired_tag}</strong> &mdash; Received {num_leads} New Leads\n",
    "            </summary>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create a table of the leads for this property\n",
    "        leads_table = group_df[['lead_contact', 'original_active_property_tag', 'timestamp']].to_html(index=False)\n",
    "        \n",
    "        details_footer = \"</details>\"\n",
    "        \n",
    "        html_parts.append(details_header + leads_table + details_footer)\n",
    "\n",
    "    # --- Build the final HTML file ---\n",
    "    final_html = f\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Complete Daily Lead Routing Report</title>\n",
    "        <style>\n",
    "            body {{ font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial, sans-serif; margin: 40px; color: #333; }}\n",
    "            h1 {{ color: #2c3e50; }}\n",
    "            details {{ \n",
    "                border: 1px solid #ddd; \n",
    "                border-radius: 8px; \n",
    "                margin-bottom: 10px; \n",
    "                overflow: hidden;\n",
    "            }}\n",
    "            summary {{ \n",
    "                padding: 15px; \n",
    "                font-size: 1.1em;\n",
    "                font-weight: bold;\n",
    "                background-color: #f7f7f7; \n",
    "                cursor: pointer;\n",
    "                outline: none;\n",
    "            }}\n",
    "            table {{ \n",
    "                width: 100%; \n",
    "                border-collapse: collapse; \n",
    "            }}\n",
    "            th, td {{ \n",
    "                padding: 12px 15px; \n",
    "                border-top: 1px solid #ddd;\n",
    "                text-align: left;\n",
    "            }}\n",
    "            th {{ \n",
    "                background-color: #f2f2f2; \n",
    "            }}\n",
    "            tr:nth-child(even) {{ \n",
    "                background-color: #fafafa; \n",
    "            }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Complete Lead Routing Report</h1>\n",
    "        <p><strong>Total Unique Leads Routed Today: {total_leads_processed}</strong></p>\n",
    "        <p>Click on each property to see the full list of leads it received. The properties are listed in order of most leads received.</p>\n",
    "        {''.join(html_parts)}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    report_path = 'full_lead_report.html'\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(final_html)\n",
    "        \n",
    "    print(f\"‚úÖ Complete analysis report has been saved to '{report_path}'.\")\n",
    "    print(\"You can now open this file in your browser to view the interactive report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39a9f830-4056-46a9-a583-0966108d2bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- üìÑ Generating Full HTML Lead Report ---\n",
      "‚úÖ Complete analysis report has been saved to 'full_lead_report.html'.\n",
      "You can now open this file in your browser to view the interactive report.\n"
     ]
    }
   ],
   "source": [
    "generate_full_lead_report(ranking_df, routing_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d23b2aad-aed4-44ca-932a-771818c228a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def categorize_tag(tag):\n",
    "    \"\"\"Categorizes a tag string based on regex patterns.\"\"\"\n",
    "    if pd.isna(tag): return 'unknown'\n",
    "    tag_str = str(tag).lower().strip()\n",
    "    if re.match(r'^\\d{2}-[a-z]{3}-\\d{2}-(99acres|magicbricks|olx|housing)', tag_str): return 'date_source_combo'\n",
    "    if re.match(r'^\\d{2}-\\d{2}-\\d{4}$', tag_str): return 'date_only'\n",
    "    if tag_str in ['sell-leads', 'cleardeals-lead', 'lead', 'recalling']: return 'generic_status'\n",
    "    if re.search(r'\\d', tag_str) and re.search(r'[a-zA-Z]', tag_str) and '-' in tag_str: return 'property_identifier'\n",
    "    return 'other'\n",
    "\n",
    "def create_property_ranking(df_property_leads, all_expired_tags):\n",
    "    \"\"\"\n",
    "    Performs feature engineering to create a sophisticated ranking score for properties.\n",
    "    \"\"\"\n",
    "    print(\"\\nüìà Engineering features for property ranking...\")\n",
    "    grouped = df_property_leads.groupby('Tags')\n",
    "    features = []\n",
    "    for tag, group in grouped:\n",
    "        if tag not in all_expired_tags: continue\n",
    "        site_visit_done_count = (group['To Lead Type'] == 'Site visit done').sum()\n",
    "        site_visit_scheduled_count = (group['To Lead Type'] == 'Site visit scheduled').sum()\n",
    "        schedule_to_done_conversion = site_visit_done_count / site_visit_scheduled_count if site_visit_scheduled_count > 0 else 0\n",
    "        group = group.sort_values('At')\n",
    "        time_diffs = group['At'].diff().dt.total_seconds() / (3600 * 24)\n",
    "        avg_days_between_interactions = time_diffs.mean()\n",
    "        features.append({\n",
    "            'Tag': tag, 'total_interactions': len(group), 'site_visit_done_count': site_visit_done_count,\n",
    "            'site_visit_scheduled_count': site_visit_scheduled_count, 'schedule_to_done_conversion': schedule_to_done_conversion,\n",
    "            'avg_days_between_interactions': avg_days_between_interactions\n",
    "        })\n",
    "\n",
    "    if not features:\n",
    "        print(\"‚ö†Ô∏è No expired properties found in the interaction data to rank.\"); return pd.DataFrame()\n",
    "        \n",
    "    ranking_df = pd.DataFrame(features).fillna(0)\n",
    "    original_features_df = ranking_df.copy()\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    cols_to_scale = ['total_interactions', 'site_visit_done_count', 'site_visit_scheduled_count', 'schedule_to_done_conversion']\n",
    "    ranking_df[cols_to_scale] = scaler.fit_transform(ranking_df[cols_to_scale])\n",
    "    ranking_df['velocity_score'] = 1 - scaler.fit_transform(ranking_df[['avg_days_between_interactions']])\n",
    "    \n",
    "    weights = {'site_visit_done_count': 0.40, 'site_visit_scheduled_count': 0.25, 'schedule_to_done_conversion': 0.15, 'velocity_score': 0.10, 'total_interactions': 0.10}\n",
    "    ranking_df['Rank_Score'] = (\n",
    "        ranking_df['site_visit_done_count'] * weights['site_visit_done_count'] +\n",
    "        ranking_df['site_visit_scheduled_count'] * weights['site_visit_scheduled_count'] +\n",
    "        ranking_df['schedule_to_done_conversion'] * weights['schedule_to_done_conversion'] +\n",
    "        ranking_df['velocity_score'] * weights['velocity_score'] +\n",
    "        ranking_df['total_interactions'] * weights['total_interactions']\n",
    "    )\n",
    "    \n",
    "    final_ranking_df = pd.merge(original_features_df, ranking_df[['Tag', 'Rank_Score']], on='Tag')\n",
    "    final_ranking_df.sort_values(by='Rank_Score', ascending=False, inplace=True)\n",
    "    final_ranking_df.reset_index(drop=True, inplace=True)\n",
    "    final_ranking_df['Overall_Rank'] = final_ranking_df.index + 1\n",
    "    \n",
    "    print(\"‚úÖ Ranking complete.\")\n",
    "    return final_ranking_df\n",
    "\n",
    "def generate_full_lead_report(ranking_df, routed_leads_df):\n",
    "    \"\"\"\n",
    "    Generates a detailed, visually appealing HTML report for all routed leads.\n",
    "    \"\"\"\n",
    "    print(\"\\n\\n--- üìÑ Generating Full HTML Lead Report ---\")\n",
    "    \n",
    "    if routed_leads_df.empty:\n",
    "        print(\"No leads were routed, so no report can be generated.\")\n",
    "        return\n",
    "\n",
    "    # --- 1. Calculate Summary Statistics ---\n",
    "    total_assignments = len(routed_leads_df)\n",
    "    lead_counts_per_property = routed_leads_df.groupby('routed_to_expired_property_tag')['lead_contact'].nunique()\n",
    "    total_properties_receiving_leads = len(lead_counts_per_property)\n",
    "    lead_distribution = lead_counts_per_property.value_counts().sort_index().reset_index()\n",
    "    lead_distribution.columns = ['Number of Leads Received', 'Number of Properties']\n",
    "\n",
    "    # --- 2. Prepare data for the detailed log ---\n",
    "    rank_map = ranking_df.set_index('Tag')['Overall_Rank'].to_dict()\n",
    "    grouped = routed_leads_df.groupby('routed_to_expired_property_tag')\n",
    "    html_parts = []\n",
    "    sorted_groups = sorted(grouped, key=lambda x: len(x[1].drop_duplicates(subset=['lead_contact'])), reverse=True)\n",
    "\n",
    "    for expired_tag, group_df in sorted_groups:\n",
    "        num_unique_leads = len(group_df.drop_duplicates(subset=['lead_contact']))\n",
    "        rank = rank_map.get(expired_tag, 'N/A')\n",
    "        details_header = f\"\"\"<details><summary><strong>Rank #{rank}: {expired_tag}</strong> &mdash; Received {num_unique_leads} Unique New Leads</summary>\"\"\"\n",
    "        leads_table = group_df[['lead_contact', 'original_active_property_tag', 'timestamp']].to_html(index=False)\n",
    "        details_footer = \"</details>\"\n",
    "        html_parts.append(details_header + leads_table + details_footer)\n",
    "\n",
    "    # --- 3. Build the final HTML file ---\n",
    "    final_html = f\"\"\"\n",
    "    <html><head><title>Complete Daily Lead Routing Report</title>\n",
    "    <style>\n",
    "        body {{ font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial, sans-serif; margin: 40px; color: #333; }}\n",
    "        h1, h2, h3 {{ color: #2c3e50; }}\n",
    "        .summary-box {{ background-color: #eaf2f8; border-left: 5px solid #3498db; padding: 15px; margin-bottom: 30px; }}\n",
    "        details {{ border: 1px solid #ddd; border-radius: 8px; margin-bottom: 10px; overflow: hidden; }}\n",
    "        summary {{ padding: 15px; font-size: 1.1em; font-weight: bold; background-color: #f7f7f7; cursor: pointer; outline: none; }}\n",
    "        table {{ width: 100%; border-collapse: collapse; }}\n",
    "        th, td {{ padding: 12px 15px; border-top: 1px solid #ddd; text-align: left; }}\n",
    "        th {{ background-color: #f2f2f2; }}\n",
    "        tr:nth-child(even) {{ background-color: #fafafa; }}\n",
    "    </style>\n",
    "    </head><body>\n",
    "    <h1>Complete Lead Routing Report</h1>\n",
    "    <h2>Summary Statistics</h2>\n",
    "    <div class=\"summary-box\">\n",
    "        <p><strong>Total Unique Leads Routed Today:</strong> {total_assignments}</p>\n",
    "        <p><strong>Total Expired Properties Receiving Leads:</strong> {total_properties_receiving_leads}</p>\n",
    "    </div>\n",
    "    <h3>Lead Distribution Breakdown</h3>\n",
    "    {lead_distribution.to_html(index=False)}\n",
    "    <h2>Detailed Lead Log</h2>\n",
    "    <p>Click on each property to see the full list of leads it received.</p>\n",
    "    {''.join(html_parts)}\n",
    "    </body></html>\n",
    "    \"\"\"\n",
    "    \n",
    "    report_path = 'full_lead_report.html'\n",
    "    with open(report_path, 'w', encoding='utf-8') as f: f.write(final_html)\n",
    "    print(f\"‚úÖ Complete analysis report has been saved to '{report_path}'.\")\n",
    "\n",
    "def route_daily_leads_prioritized():\n",
    "    \"\"\"\n",
    "    Routes new leads using a Priority Queue model to ensure the best-ranked\n",
    "    properties get the first opportunity.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting daily lead routing with PRIORITY QUEUE logic...\")\n",
    "    \n",
    "    try:\n",
    "        with open('matches.json', 'r') as f: expired_to_active_matches = json.load(f)\n",
    "        df_changes = pd.read_csv('ContactTypeChange.csv', low_memory=False)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error: Missing a required file. {e}\"); return\n",
    "\n",
    "    print(\"\\nüîç Cleaning and filtering lead interaction tags...\")\n",
    "    df_changes['tag_type'] = df_changes['Tags'].apply(categorize_tag)\n",
    "    df_property_leads = df_changes[df_changes['tag_type'] == 'property_identifier'].copy()\n",
    "    df_property_leads['At'] = pd.to_datetime(df_property_leads['At'], errors='coerce')\n",
    "    print(f\"‚úÖ Found {len(df_property_leads)} interactions linked to specific properties.\")\n",
    "\n",
    "    all_expired_tags = list(expired_to_active_matches.keys())\n",
    "    ranking_df = create_property_ranking(df_property_leads, all_expired_tags)\n",
    "    if ranking_df.empty: return\n",
    "    \n",
    "    most_recent_date = df_property_leads['At'].max().date()\n",
    "    daily_leads = df_property_leads[df_property_leads['At'].dt.date == most_recent_date]\n",
    "    print(f\"\\nüóìÔ∏è Simulating daily run for date: {most_recent_date}\")\n",
    "\n",
    "    active_to_expired_map = defaultdict(list)\n",
    "    for expired_tag, active_tags in expired_to_active_matches.items():\n",
    "        for active_tag in active_tags:\n",
    "            active_to_expired_map[active_tag].append(expired_tag)\n",
    "\n",
    "    routed_leads = []; daily_assignments = defaultdict(set); daily_lead_caps = defaultdict(int)\n",
    "    MAX_LEADS_PER_DAY = 7\n",
    "\n",
    "    for _, lead in daily_leads.iterrows():\n",
    "        active_prop_tag = lead['Tags']\n",
    "        lead_contact = lead['Contact']\n",
    "        \n",
    "        if active_prop_tag in active_to_expired_map:\n",
    "            candidate_expired_props = active_to_expired_map[active_prop_tag]\n",
    "            \n",
    "            # Filter out properties with no rank\n",
    "            ranked_candidates = [tag for tag in candidate_expired_props if tag in ranking_df['Tag'].values]\n",
    "            \n",
    "            # Sort candidates by their overall rank (lower is better)\n",
    "            ranked_candidates.sort(key=lambda tag: ranking_df.loc[ranking_df['Tag'] == tag, 'Overall_Rank'].iloc[0])\n",
    "\n",
    "            # Iterate through the sorted candidates and assign the lead to the first one available\n",
    "            for assigned_tag in ranked_candidates:\n",
    "                if lead_contact not in daily_assignments[assigned_tag] and daily_lead_caps[assigned_tag] < MAX_LEADS_PER_DAY:\n",
    "                    # Assign the lead to this property\n",
    "                    routed_leads.append({'lead_contact': lead_contact, 'original_active_property_tag': active_prop_tag, 'routed_to_expired_property_tag': assigned_tag, 'timestamp': lead['At']})\n",
    "                    daily_assignments[assigned_tag].add(lead_contact)\n",
    "                    daily_lead_caps[assigned_tag] += 1\n",
    "                    # IMPORTANT: Break the loop once the lead is assigned to prevent broadcasting\n",
    "                    break\n",
    "                        \n",
    "    if routed_leads:\n",
    "        routing_results_df = pd.DataFrame(routed_leads)\n",
    "        print(f\"\\n‚úÖ Lead routing complete. Created {len(routing_results_df)} new lead assignments.\")\n",
    "        generate_full_lead_report(ranking_df, routing_results_df)\n",
    "    else:\n",
    "        print(\"\\n‚ÑπÔ∏è No new leads were routed today for the matched properties.\")\n",
    "\n",
    "# --- How to run this ---\n",
    "# route_daily_leads_prioritized()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c97797d-15ec-4615-84bf-89e85da37dd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting daily lead routing with PRIORITY QUEUE logic...\n",
      "\n",
      "üîç Cleaning and filtering lead interaction tags...\n",
      "‚úÖ Found 74902 interactions linked to specific properties.\n",
      "\n",
      "üìà Engineering features for property ranking...\n",
      "‚úÖ Ranking complete.\n",
      "\n",
      "üóìÔ∏è Simulating daily run for date: 2025-07-31\n",
      "\n",
      "‚úÖ Lead routing complete. Created 240 new lead assignments.\n",
      "\n",
      "\n",
      "--- üìÑ Generating Full HTML Lead Report ---\n",
      "‚úÖ Complete analysis report has been saved to 'full_lead_report.html'.\n"
     ]
    }
   ],
   "source": [
    "route_daily_leads_prioritized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756c6a8a-2d68-4486-80f5-0a7dd9bdcd55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bbce7a-ad5e-473a-8d9c-60edbadda3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba13b1-f0b9-44ec-841a-e3d13a15074c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
