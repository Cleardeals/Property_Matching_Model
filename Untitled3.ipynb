{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f67ee01-a120-46b3-b81c-ee54385ceab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "def categorize_tag(tag):\n",
    "    \"\"\"Categorizes a tag string based on regex patterns.\"\"\"\n",
    "    if pd.isna(tag): return 'unknown'\n",
    "    tag_str = str(tag).lower().strip()\n",
    "    if re.match(r'^\\d{2}-[a-z]{3}-\\d{2}-(99acres|magicbricks|olx|housing)', tag_str): return 'date_source_combo'\n",
    "    if re.match(r'^\\d{2}-\\d{2}-\\d{4}$', tag_str): return 'date_only'\n",
    "    if tag_str in ['sell-leads', 'cleardeals-lead', 'lead', 'recalling']: return 'generic_status'\n",
    "    if re.search(r'\\d', tag_str) and re.search(r'[a-zA-Z]', tag_str) and '-' in tag_str: return 'property_identifier'\n",
    "    return 'other'\n",
    "\n",
    "def parse_custom_date(date_str):\n",
    "    \"\"\"Parses dates like 'Aug 21st 2024, 12:55 PM' with ordinal suffixes.\"\"\"\n",
    "    if pd.isna(date_str): return pd.NaT\n",
    "    try:\n",
    "        date_str = re.sub(r'(\\d+)(st|nd|rd|th)', r'\\1', date_str)\n",
    "        return pd.to_datetime(date_str, format='%b %d %Y, %I:%M %p', errors='coerce')\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def create_property_ranking(df_property_leads, all_expired_tags):\n",
    "    \"\"\"\n",
    "    Creates a ranking score for expired properties based on historical lead activity.\n",
    "    Uses full historical data for features, with recency weighting.\n",
    "    \"\"\"\n",
    "    print(\"\\nüìà Engineering features for property ranking...\")\n",
    "    ref_date = pd.to_datetime('2024-08-23')\n",
    "    six_months_ago = ref_date - timedelta(days=180)\n",
    "\n",
    "    grouped = df_property_leads.groupby('Tags')\n",
    "    features = []\n",
    "    for tag, group in grouped:\n",
    "        if tag not in all_expired_tags: continue\n",
    "        total_interactions = len(group)\n",
    "        site_visit_done_count = (group['To Lead Type'] == 'Site visit done').sum()\n",
    "        site_visit_scheduled_count = (group['To Lead Type'] == 'Site visit scheduled').sum()\n",
    "        schedule_to_done_conversion = site_visit_done_count / site_visit_scheduled_count if site_visit_scheduled_count > 0 else 0\n",
    "        time_diffs = group['At'].diff().dt.total_seconds() / (3600 * 24)\n",
    "        avg_days_between_interactions = time_diffs.mean() if not time_diffs.empty else float('inf')\n",
    "        recency_weight = 1.0 if group['At'].max() >= six_months_ago else 0.5\n",
    "        features.append({\n",
    "            'Tag': tag,\n",
    "            'total_interactions': total_interactions,\n",
    "            'site_visit_done_count': site_visit_done_count,\n",
    "            'site_visit_scheduled_count': site_visit_scheduled_count,\n",
    "            'schedule_to_done_conversion': schedule_to_done_conversion,\n",
    "            'avg_days_between_interactions': avg_days_between_interactions,\n",
    "            'recency_weight': recency_weight\n",
    "        })\n",
    "\n",
    "    if not features:\n",
    "        print(\"‚ö†Ô∏è No expired properties found in the interaction data to rank.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    ranking_df = pd.DataFrame(features).fillna({\n",
    "        'total_interactions': 0,\n",
    "        'site_visit_done_count': 0,\n",
    "        'site_visit_scheduled_count': 0,\n",
    "        'schedule_to_done_conversion': 0,\n",
    "        'avg_days_between_interactions': float('inf')\n",
    "    })\n",
    "    original_features_df = ranking_df.copy()\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    cols_to_scale = ['total_interactions', 'site_visit_done_count', 'site_visit_scheduled_count', 'schedule_to_done_conversion']\n",
    "    ranking_df[cols_to_scale] = scaler.fit_transform(ranking_df[cols_to_scale])\n",
    "    ranking_df['velocity_score'] = 1 - scaler.fit_transform(ranking_df[['avg_days_between_interactions']].replace(float('inf'), 1000))\n",
    "    \n",
    "    weights = {\n",
    "        'site_visit_done_count': 0.35,\n",
    "        'site_visit_scheduled_count': 0.25,\n",
    "        'schedule_to_done_conversion': 0.15,\n",
    "        'velocity_score': 0.15,\n",
    "        'total_interactions': 0.10\n",
    "    }\n",
    "    ranking_df['Rank_Score'] = (\n",
    "        ranking_df['site_visit_done_count'] * weights['site_visit_done_count'] +\n",
    "        ranking_df['site_visit_scheduled_count'] * weights['site_visit_scheduled_count'] +\n",
    "        ranking_df['schedule_to_done_conversion'] * weights['schedule_to_done_conversion'] +\n",
    "        ranking_df['velocity_score'] * weights['velocity_score'] +\n",
    "        ranking_df['total_interactions'] * weights['total_interactions']\n",
    "    ) * ranking_df['recency_weight']\n",
    "    \n",
    "    final_ranking_df = pd.merge(original_features_df, ranking_df[['Tag', 'Rank_Score']], on='Tag')\n",
    "    final_ranking_df.sort_values(by='Rank_Score', ascending=False, inplace=True)\n",
    "    final_ranking_df.reset_index(drop=True, inplace=True)\n",
    "    final_ranking_df['Overall_Rank'] = final_ranking_df.index + 1\n",
    "    \n",
    "    return final_ranking_df\n",
    "\n",
    "def generate_plot_base64(lead_distribution):\n",
    "    \"\"\"Generates a base64-encoded PNG of the lead distribution bar chart.\"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.countplot(x='Number of Leads Received', data=lead_distribution)\n",
    "    plt.title('Lead Distribution Across Properties')\n",
    "    plt.xlabel('Number of Leads Received')\n",
    "    plt.ylabel('Number of Properties')\n",
    "    buffer = BytesIO()\n",
    "    plt.savefig(buffer, format='png')\n",
    "    plt.close()\n",
    "    buffer.seek(0)\n",
    "    return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "def generate_weekly_lead_report(ranking_df, routed_leads_df, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generates a detailed HTML report for weekly lead assignments with visualizations.\n",
    "    \"\"\"\n",
    "    print(\"\\nüìÑ Generating Weekly HTML Lead Report ---\")\n",
    "    \n",
    "    if routed_leads_df.empty:\n",
    "        print(\"No leads were routed, so no report can be generated.\")\n",
    "        return\n",
    "\n",
    "    total_assignments = len(routed_leads_df)\n",
    "    lead_counts_per_property = routed_leads_df.groupby('routed_to_expired_property_tag')['lead_contact'].nunique()\n",
    "    total_properties_receiving_leads = len(lead_counts_per_property)\n",
    "    lead_distribution = lead_counts_per_property.value_counts().sort_index().reset_index()\n",
    "    lead_distribution.columns = ['Number of Leads Received', 'Number of Properties']\n",
    "\n",
    "    plot_base64 = generate_plot_base64(lead_distribution)\n",
    "\n",
    "    rank_map = ranking_df.set_index('Tag')['Overall_Rank'].to_dict()\n",
    "    grouped = routed_leads_df.groupby('routed_to_expired_property_tag')\n",
    "    html_parts = []\n",
    "    sorted_groups = sorted(grouped, key=lambda x: len(x[1].drop_duplicates(subset=['lead_contact'])), reverse=True)\n",
    "\n",
    "    for expired_tag, group_df in sorted_groups:\n",
    "        num_unique_leads = len(group_df.drop_duplicates(subset=['lead_contact']))\n",
    "        rank = rank_map.get(expired_tag, 'N/A')\n",
    "        details_header = f\"\"\"<details><summary><strong>Rank #{rank}: {expired_tag}</strong> &mdash; Received {num_unique_leads} Unique Leads</summary>\"\"\"\n",
    "        leads_table = group_df[['lead_contact', 'original_active_property_tag', 'timestamp']].to_html(index=False)\n",
    "        details_footer = \"</details>\"\n",
    "        html_parts.append(details_header + leads_table + details_footer)\n",
    "\n",
    "    final_html = f\"\"\"\n",
    "    <html><head><title>Weekly Lead Routing Report ({start_date} to {end_date})</title>\n",
    "    <style>\n",
    "        body {{ font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial, sans-serif; margin: 40px; color: #333; }}\n",
    "        h1, h2, h3 {{ color: #2c3e50; }}\n",
    "        .summary-box {{ background-color: #eaf2f8; border-left: 5px solid #3498db; padding: 15px; margin-bottom: 30px; }}\n",
    "        details {{ border: 1px solid #ddd; border-radius: 8px; margin-bottom: 10px; overflow: hidden; }}\n",
    "        summary {{ padding: 15px; font-size: 1.1em; font-weight: bold; background-color: #f7f7f7; cursor: pointer; outline: none; }}\n",
    "        table {{ width: 100%; border-collapse: collapse; }}\n",
    "        th, td {{ padding: 12px 15px; border-top: 1px solid #ddd; text-align: left; }}\n",
    "        th {{ background-color: #f2f2f2; }}\n",
    "        tr:nth-child(even) {{ background-color: #fafafa; }}\n",
    "        img {{ max-width: 100%; height: auto; margin-top: 20px; }}\n",
    "    </style>\n",
    "    </head><body>\n",
    "    <h1>Weekly Lead Routing Report ({start_date} to {end_date})</h1>\n",
    "    <h2>Summary Statistics</h2>\n",
    "    <div class=\"summary-box\">\n",
    "        <p><strong>Total Unique Leads Routed:</strong> {total_assignments}</p>\n",
    "        <p><strong>Total Expired Properties Receiving Leads:</strong> {total_properties_receiving_leads}</p>\n",
    "    </div>\n",
    "    <h3>Lead Distribution Breakdown</h3>\n",
    "    {lead_distribution.to_html(index=False)}\n",
    "    <h3>Lead Distribution Visualization</h3>\n",
    "    <img src=\"data:image/png;base64,{plot_base64}\" alt=\"Lead Distribution\">\n",
    "    <h2>Detailed Lead Log</h2>\n",
    "    <p>Click on each property to see the full list of leads it received.</p>\n",
    "    {''.join(html_parts)}\n",
    "    </body></html>\n",
    "    \"\"\"\n",
    "    \n",
    "    report_path = 'weekly_lead_report.html'\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(final_html)\n",
    "    print(f\"‚úÖ Weekly report saved to '{report_path}'.\")\n",
    "    routed_leads_df.to_csv('weekly_routed_leads.csv', index=False)\n",
    "    print(f\"‚úÖ Routed leads saved to 'weekly_routed_leads.csv'.\")\n",
    "\n",
    "def route_weekly_leads_prioritized():\n",
    "    \"\"\"\n",
    "    Routes leads for one week (Aug 17‚Äì23, 2024) using a dynamic priority queue model.\n",
    "    High lead volume: Prioritize high-ranked properties.\n",
    "    Low lead volume: Distribute evenly across similar expired properties.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting weekly lead routing with dynamic priority queue logic...\")\n",
    "    \n",
    "    try:\n",
    "        with open('active_to_expired_mapping.json', 'r') as f:\n",
    "            active_to_expired_matches = json.load(f)\n",
    "        df_changes = pd.read_csv('ContactTypeChange.csv', low_memory=False)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error: Missing a required file. {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nüîç Cleaning and filtering lead interaction tags...\")\n",
    "    df_changes['At'] = df_changes['At'].apply(parse_custom_date)\n",
    "    df_changes['tag_type'] = df_changes['Tags'].apply(categorize_tag)\n",
    "    df_property_leads = df_changes[df_changes['tag_type'] == 'property_identifier'].copy()\n",
    "    print(f\"‚úÖ Found {len(df_property_leads)} interactions linked to specific properties.\")\n",
    "    print(\"Sample timestamps after parsing:\")\n",
    "    print(df_property_leads[['Tags', 'At']].head())\n",
    "\n",
    "    all_expired_tags = set()\n",
    "    active_to_expired_map = defaultdict(list)\n",
    "    for active_tag, matches in active_to_expired_matches.items():\n",
    "        active_tag_clean = active_tag.split('_')[0]  # Remove _index suffix\n",
    "        for match in matches:\n",
    "            expired_tag = match['expired_tag']\n",
    "            expired_tag_clean = expired_tag.split('_')[0]  # Strip _index from expired tags\n",
    "            all_expired_tags.add(expired_tag_clean)\n",
    "            active_to_expired_map[active_tag_clean].append(expired_tag_clean)\n",
    "    print(f\"Found {len(all_expired_tags)} unique expired property tags (cleaned).\")\n",
    "    print(\"Sample active-to-expired mappings (after cleaning tags):\")\n",
    "    for active_tag in list(active_to_expired_map.keys())[:5]:\n",
    "        print(f\"Active {active_tag}: {active_to_expired_map[active_tag][:3]}\")\n",
    "\n",
    "    # Clean Tags in df_property_leads to match\n",
    "    df_property_leads['Tags'] = df_property_leads['Tags'].apply(lambda tag: tag.split('_')[0] if '_' in str(tag) else tag)\n",
    "\n",
    "    lead_tags = set(df_property_leads['Tags'])\n",
    "    active_tags = set(active_to_expired_map.keys())\n",
    "    matching_tags = lead_tags.intersection(active_tags)\n",
    "    print(f\"Lead tags in ContactTypeChange.csv: {len(lead_tags)}\")\n",
    "    print(f\"Active tags in active_to_expired_mapping.json (cleaned): {len(active_tags)}\")\n",
    "    print(f\"Matching tags: {len(matching_tags)}\")\n",
    "    if matching_tags:\n",
    "        print(\"Sample matching tags:\", list(matching_tags)[:5])\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No matching tags found. Check tag formats in ContactTypeChange.csv and active_to_expired_mapping.json.\")\n",
    "\n",
    "    ranking_df = create_property_ranking(df_property_leads, all_expired_tags)\n",
    "    if ranking_df.empty:\n",
    "        print(\"‚ö†Ô∏è No ranking data available. Using default ranking for all expired properties.\")\n",
    "        ranking_df = pd.DataFrame({'Tag': list(all_expired_tags), 'Rank_Score': 0.5, 'Overall_Rank': range(1, len(all_expired_tags) + 1)})\n",
    "\n",
    "    start_date = pd.to_datetime('2024-08-17')\n",
    "    end_date = pd.to_datetime('2024-08-23')\n",
    "    weekly_leads = df_property_leads[(df_property_leads['At'].dt.date >= start_date.date()) & (df_property_leads['At'].dt.date <= end_date.date())]\n",
    "    print(f\"\\nüóìÔ∏è Processing leads for week: {start_date.date()} to {end_date.date()}\")\n",
    "    print(f\"Total leads in week: {len(weekly_leads)}\")\n",
    "    if len(weekly_leads) == 0:\n",
    "        print(\"‚ö†Ô∏è No leads found in the specified week. Check timestamp format or date range in ContactTypeChange.csv.\")\n",
    "        print(\"Available timestamp range:\", df_property_leads['At'].min(), \"to\", df_property_leads['At'].max())\n",
    "\n",
    "    routed_leads = []\n",
    "    weekly_assignments = defaultdict(set)\n",
    "    weekly_lead_caps = defaultdict(int)\n",
    "    MAX_LEADS_PER_WEEK = 49  # 7 leads/day * 7 days\n",
    "    HIGH_VOLUME_THRESHOLD = 2  # Leads per similar expired property per active property\n",
    "\n",
    "    for _, lead in weekly_leads.iterrows():\n",
    "        active_prop_tag = lead['Tags']\n",
    "        lead_contact = lead['Contact']\n",
    "        \n",
    "        if active_prop_tag in active_to_expired_map:\n",
    "            candidate_expired_props = active_to_expired_map[active_prop_tag]\n",
    "            num_candidates = len(candidate_expired_props)\n",
    "            \n",
    "            is_high_volume = (len(weekly_leads[weekly_leads['Tags'] == active_prop_tag]) / num_candidates) > HIGH_VOLUME_THRESHOLD if num_candidates > 0 else False\n",
    "            \n",
    "            if is_high_volume:\n",
    "                ranked_candidates = [tag for tag in candidate_expired_props if tag in ranking_df['Tag'].values]\n",
    "                ranked_candidates.sort(key=lambda tag: ranking_df.loc[ranking_df['Tag'] == tag, 'Overall_Rank'].iloc[0] if tag in ranking_df['Tag'].values else float('inf'))\n",
    "                unranked_candidates = [tag for tag in candidate_expired_props if tag not in ranking_df['Tag'].values]\n",
    "                ranked_candidates.extend(unranked_candidates)\n",
    "                \n",
    "                for assigned_tag in ranked_candidates:\n",
    "                    if lead_contact not in weekly_assignments[assigned_tag] and weekly_lead_caps[assigned_tag] < MAX_LEADS_PER_WEEK:\n",
    "                        routed_leads.append({\n",
    "                            'lead_contact': lead_contact,\n",
    "                            'original_active_property_tag': active_prop_tag,\n",
    "                            'routed_to_expired_property_tag': assigned_tag,\n",
    "                            'timestamp': lead['At']\n",
    "                        })\n",
    "                        weekly_assignments[assigned_tag].add(lead_contact)\n",
    "                        weekly_lead_caps[assigned_tag] += 1\n",
    "                        break\n",
    "            else:\n",
    "                for i, assigned_tag in enumerate(candidate_expired_props):\n",
    "                    if lead_contact not in weekly_assignments[assigned_tag] and weekly_lead_caps[assigned_tag] < MAX_LEADS_PER_WEEK:\n",
    "                        routed_leads.append({\n",
    "                            'lead_contact': lead_contact,\n",
    "                            'original_active_property_tag': active_prop_tag,\n",
    "                            'routed_to_expired_property_tag': assigned_tag,\n",
    "                            'timestamp': lead['At']\n",
    "                        })\n",
    "                        weekly_assignments[assigned_tag].add(lead_contact)\n",
    "                        weekly_lead_caps[assigned_tag] += 1\n",
    "                        break\n",
    "\n",
    "    if routed_leads:\n",
    "        routing_results_df = pd.DataFrame(routed_leads)\n",
    "        print(f\"\\n‚úÖ Lead routing complete. Created {len(routing_results_df)} new lead assignments.\")\n",
    "        generate_weekly_lead_report(ranking_df, routing_results_df, start_date.date(), end_date.date())\n",
    "    else:\n",
    "        print(\"\\n‚ÑπÔ∏è No new leads were routed for the matched properties.\")\n",
    "\n",
    "# --- How to run this ---\n",
    "# route_weekly_leads_prioritized()import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "def categorize_tag(tag):\n",
    "    \"\"\"Categorizes a tag string based on regex patterns.\"\"\"\n",
    "    if pd.isna(tag): return 'unknown'\n",
    "    tag_str = str(tag).lower().strip()\n",
    "    if re.match(r'^\\d{2}-[a-z]{3}-\\d{2}-(99acres|magicbricks|olx|housing)', tag_str): return 'date_source_combo'\n",
    "    if re.match(r'^\\d{2}-\\d{2}-\\d{4}$', tag_str): return 'date_only'\n",
    "    if tag_str in ['sell-leads', 'cleardeals-lead', 'lead', 'recalling']: return 'generic_status'\n",
    "    if re.search(r'\\d', tag_str) and re.search(r'[a-zA-Z]', tag_str) and '-' in tag_str: return 'property_identifier'\n",
    "    return 'other'\n",
    "\n",
    "def parse_custom_date(date_str):\n",
    "    \"\"\"Parses dates like 'Aug 21st 2024, 12:55 PM' with ordinal suffixes.\"\"\"\n",
    "    if pd.isna(date_str): return pd.NaT\n",
    "    try:\n",
    "        date_str = re.sub(r'(\\d+)(st|nd|rd|th)', r'\\1', date_str)\n",
    "        return pd.to_datetime(date_str, format='%b %d %Y, %I:%M %p', errors='coerce')\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def create_property_ranking(df_property_leads, all_expired_tags):\n",
    "    \"\"\"\n",
    "    Creates a ranking score for expired properties based on historical lead activity.\n",
    "    Uses full historical data for features, with recency weighting.\n",
    "    \"\"\"\n",
    "    print(\"\\nüìà Engineering features for property ranking...\")\n",
    "    ref_date = pd.to_datetime('2024-08-23')\n",
    "    six_months_ago = ref_date - timedelta(days=180)\n",
    "\n",
    "    grouped = df_property_leads.groupby('Tags')\n",
    "    features = []\n",
    "    for tag, group in grouped:\n",
    "        if tag not in all_expired_tags: continue\n",
    "        total_interactions = len(group)\n",
    "        site_visit_done_count = (group['To Lead Type'] == 'Site visit done').sum()\n",
    "        site_visit_scheduled_count = (group['To Lead Type'] == 'Site visit scheduled').sum()\n",
    "        schedule_to_done_conversion = site_visit_done_count / site_visit_scheduled_count if site_visit_scheduled_count > 0 else 0\n",
    "        time_diffs = group['At'].diff().dt.total_seconds() / (3600 * 24)\n",
    "        avg_days_between_interactions = time_diffs.mean() if not time_diffs.empty else float('inf')\n",
    "        recency_weight = 1.0 if group['At'].max() >= six_months_ago else 0.5\n",
    "        features.append({\n",
    "            'Tag': tag,\n",
    "            'total_interactions': total_interactions,\n",
    "            'site_visit_done_count': site_visit_done_count,\n",
    "            'site_visit_scheduled_count': site_visit_scheduled_count,\n",
    "            'schedule_to_done_conversion': schedule_to_done_conversion,\n",
    "            'avg_days_between_interactions': avg_days_between_interactions,\n",
    "            'recency_weight': recency_weight\n",
    "        })\n",
    "\n",
    "    if not features:\n",
    "        print(\"‚ö†Ô∏è No expired properties found in the interaction data to rank.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    ranking_df = pd.DataFrame(features).fillna({\n",
    "        'total_interactions': 0,\n",
    "        'site_visit_done_count': 0,\n",
    "        'site_visit_scheduled_count': 0,\n",
    "        'schedule_to_done_conversion': 0,\n",
    "        'avg_days_between_interactions': float('inf')\n",
    "    })\n",
    "    original_features_df = ranking_df.copy()\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    cols_to_scale = ['total_interactions', 'site_visit_done_count', 'site_visit_scheduled_count', 'schedule_to_done_conversion']\n",
    "    ranking_df[cols_to_scale] = scaler.fit_transform(ranking_df[cols_to_scale])\n",
    "    ranking_df['velocity_score'] = 1 - scaler.fit_transform(ranking_df[['avg_days_between_interactions']].replace(float('inf'), 1000))\n",
    "    \n",
    "    weights = {\n",
    "        'site_visit_done_count': 0.35,\n",
    "        'site_visit_scheduled_count': 0.25,\n",
    "        'schedule_to_done_conversion': 0.15,\n",
    "        'velocity_score': 0.15,\n",
    "        'total_interactions': 0.10\n",
    "    }\n",
    "    ranking_df['Rank_Score'] = (\n",
    "        ranking_df['site_visit_done_count'] * weights['site_visit_done_count'] +\n",
    "        ranking_df['site_visit_scheduled_count'] * weights['site_visit_scheduled_count'] +\n",
    "        ranking_df['schedule_to_done_conversion'] * weights['schedule_to_done_conversion'] +\n",
    "        ranking_df['velocity_score'] * weights['velocity_score'] +\n",
    "        ranking_df['total_interactions'] * weights['total_interactions']\n",
    "    ) * ranking_df['recency_weight']\n",
    "    \n",
    "    final_ranking_df = pd.merge(original_features_df, ranking_df[['Tag', 'Rank_Score']], on='Tag')\n",
    "    final_ranking_df.sort_values(by='Rank_Score', ascending=False, inplace=True)\n",
    "    final_ranking_df.reset_index(drop=True, inplace=True)\n",
    "    final_ranking_df['Overall_Rank'] = final_ranking_df.index + 1\n",
    "    \n",
    "    return final_ranking_df\n",
    "\n",
    "def generate_plot_base64(lead_distribution):\n",
    "    \"\"\"Generates a base64-encoded PNG of the lead distribution bar chart.\"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.countplot(x='Number of Leads Received', data=lead_distribution)\n",
    "    plt.title('Lead Distribution Across Properties')\n",
    "    plt.xlabel('Number of Leads Received')\n",
    "    plt.ylabel('Number of Properties')\n",
    "    buffer = BytesIO()\n",
    "    plt.savefig(buffer, format='png')\n",
    "    plt.close()\n",
    "    buffer.seek(0)\n",
    "    return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "def generate_weekly_lead_report(ranking_df, routed_leads_df, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generates a detailed HTML report for weekly lead assignments with visualizations.\n",
    "    \"\"\"\n",
    "    print(\"\\nüìÑ Generating Weekly HTML Lead Report ---\")\n",
    "    \n",
    "    if routed_leads_df.empty:\n",
    "        print(\"No leads were routed, so no report can be generated.\")\n",
    "        return\n",
    "\n",
    "    total_assignments = len(routed_leads_df)\n",
    "    lead_counts_per_property = routed_leads_df.groupby('routed_to_expired_property_tag')['lead_contact'].nunique()\n",
    "    total_properties_receiving_leads = len(lead_counts_per_property)\n",
    "    lead_distribution = lead_counts_per_property.value_counts().sort_index().reset_index()\n",
    "    lead_distribution.columns = ['Number of Leads Received', 'Number of Properties']\n",
    "\n",
    "    plot_base64 = generate_plot_base64(lead_distribution)\n",
    "\n",
    "    rank_map = ranking_df.set_index('Tag')['Overall_Rank'].to_dict()\n",
    "    grouped = routed_leads_df.groupby('routed_to_expired_property_tag')\n",
    "    html_parts = []\n",
    "    sorted_groups = sorted(grouped, key=lambda x: len(x[1].drop_duplicates(subset=['lead_contact'])), reverse=True)\n",
    "\n",
    "    for expired_tag, group_df in sorted_groups:\n",
    "        num_unique_leads = len(group_df.drop_duplicates(subset=['lead_contact']))\n",
    "        rank = rank_map.get(expired_tag, 'N/A')\n",
    "        details_header = f\"\"\"<details><summary><strong>Rank #{rank}: {expired_tag}</strong> &mdash; Received {num_unique_leads} Unique Leads</summary>\"\"\"\n",
    "        leads_table = group_df[['lead_contact', 'original_active_property_tag', 'timestamp']].to_html(index=False)\n",
    "        details_footer = \"</details>\"\n",
    "        html_parts.append(details_header + leads_table + details_footer)\n",
    "\n",
    "    final_html = f\"\"\"\n",
    "    <html><head><title>Weekly Lead Routing Report ({start_date} to {end_date})</title>\n",
    "    <style>\n",
    "        body {{ font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial, sans-serif; margin: 40px; color: #333; }}\n",
    "        h1, h2, h3 {{ color: #2c3e50; }}\n",
    "        .summary-box {{ background-color: #eaf2f8; border-left: 5px solid #3498db; padding: 15px; margin-bottom: 30px; }}\n",
    "        details {{ border: 1px solid #ddd; border-radius: 8px; margin-bottom: 10px; overflow: hidden; }}\n",
    "        summary {{ padding: 15px; font-size: 1.1em; font-weight: bold; background-color: #f7f7f7; cursor: pointer; outline: none; }}\n",
    "        table {{ width: 100%; border-collapse: collapse; }}\n",
    "        th, td {{ padding: 12px 15px; border-top: 1px solid #ddd; text-align: left; }}\n",
    "        th {{ background-color: #f2f2f2; }}\n",
    "        tr:nth-child(even) {{ background-color: #fafafa; }}\n",
    "        img {{ max-width: 100%; height: auto; margin-top: 20px; }}\n",
    "    </style>\n",
    "    </head><body>\n",
    "    <h1>Weekly Lead Routing Report ({start_date} to {end_date})</h1>\n",
    "    <h2>Summary Statistics</h2>\n",
    "    <div class=\"summary-box\">\n",
    "        <p><strong>Total Unique Leads Routed:</strong> {total_assignments}</p>\n",
    "        <p><strong>Total Expired Properties Receiving Leads:</strong> {total_properties_receiving_leads}</p>\n",
    "    </div>\n",
    "    <h3>Lead Distribution Breakdown</h3>\n",
    "    {lead_distribution.to_html(index=False)}\n",
    "    <h3>Lead Distribution Visualization</h3>\n",
    "    <img src=\"data:image/png;base64,{plot_base64}\" alt=\"Lead Distribution\">\n",
    "    <h2>Detailed Lead Log</h2>\n",
    "    <p>Click on each property to see the full list of leads it received.</p>\n",
    "    {''.join(html_parts)}\n",
    "    </body></html>\n",
    "    \"\"\"\n",
    "    \n",
    "    report_path = 'weekly_lead_report.html'\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(final_html)\n",
    "    print(f\"‚úÖ Weekly report saved to '{report_path}'.\")\n",
    "    routed_leads_df.to_csv('weekly_routed_leads.csv', index=False)\n",
    "    print(f\"‚úÖ Routed leads saved to 'weekly_routed_leads.csv'.\")\n",
    "\n",
    "def route_weekly_leads_prioritized():\n",
    "    \"\"\"\n",
    "    Routes leads for one week (Aug 17‚Äì23, 2024) using a dynamic priority queue model.\n",
    "    High lead volume: Prioritize high-ranked properties.\n",
    "    Low lead volume: Distribute evenly across similar expired properties.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting weekly lead routing with dynamic priority queue logic...\")\n",
    "    \n",
    "    try:\n",
    "        with open('active_to_expired_mapping.json', 'r') as f:\n",
    "            active_to_expired_matches = json.load(f)\n",
    "        df_changes = pd.read_csv('ContactTypeChange.csv', low_memory=False)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error: Missing a required file. {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nüîç Cleaning and filtering lead interaction tags...\")\n",
    "    df_changes['At'] = df_changes['At'].apply(parse_custom_date)\n",
    "    df_changes['tag_type'] = df_changes['Tags'].apply(categorize_tag)\n",
    "    df_property_leads = df_changes[df_changes['tag_type'] == 'property_identifier'].copy()\n",
    "    print(f\"‚úÖ Found {len(df_property_leads)} interactions linked to specific properties.\")\n",
    "    print(\"Sample timestamps after parsing:\")\n",
    "    print(df_property_leads[['Tags', 'At']].head())\n",
    "\n",
    "    all_expired_tags = set()\n",
    "    active_to_expired_map = defaultdict(list)\n",
    "    for active_tag, matches in active_to_expired_matches.items():\n",
    "        active_tag_clean = active_tag.split('_')[0]  # Remove _index suffix\n",
    "        for match in matches:\n",
    "            expired_tag = match['expired_tag']\n",
    "            expired_tag_clean = expired_tag.split('_')[0]  # Strip _index from expired tags\n",
    "            all_expired_tags.add(expired_tag_clean)\n",
    "            active_to_expired_map[active_tag_clean].append(expired_tag_clean)\n",
    "    print(f\"Found {len(all_expired_tags)} unique expired property tags (cleaned).\")\n",
    "    print(\"Sample active-to-expired mappings (after cleaning tags):\")\n",
    "    for active_tag in list(active_to_expired_map.keys())[:5]:\n",
    "        print(f\"Active {active_tag}: {active_to_expired_map[active_tag][:3]}\")\n",
    "\n",
    "    # Clean Tags in df_property_leads to match\n",
    "    df_property_leads['Tags'] = df_property_leads['Tags'].apply(lambda tag: tag.split('_')[0] if '_' in str(tag) else tag)\n",
    "\n",
    "    lead_tags = set(df_property_leads['Tags'])\n",
    "    active_tags = set(active_to_expired_map.keys())\n",
    "    matching_tags = lead_tags.intersection(active_tags)\n",
    "    print(f\"Lead tags in ContactTypeChange.csv: {len(lead_tags)}\")\n",
    "    print(f\"Active tags in active_to_expired_mapping.json (cleaned): {len(active_tags)}\")\n",
    "    print(f\"Matching tags: {len(matching_tags)}\")\n",
    "    if matching_tags:\n",
    "        print(\"Sample matching tags:\", list(matching_tags)[:5])\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No matching tags found. Check tag formats in ContactTypeChange.csv and active_to_expired_mapping.json.\")\n",
    "\n",
    "    ranking_df = create_property_ranking(df_property_leads, all_expired_tags)\n",
    "    if ranking_df.empty:\n",
    "        print(\"‚ö†Ô∏è No ranking data available. Using default ranking for all expired properties.\")\n",
    "        ranking_df = pd.DataFrame({'Tag': list(all_expired_tags), 'Rank_Score': 0.5, 'Overall_Rank': range(1, len(all_expired_tags) + 1)})\n",
    "\n",
    "    start_date = pd.to_datetime('2025-08-17')\n",
    "    end_date = pd.to_datetime('2025-08-23')\n",
    "    weekly_leads = df_property_leads[(df_property_leads['At'].dt.date >= start_date.date()) & (df_property_leads['At'].dt.date <= end_date.date())]\n",
    "    print(f\"\\nüóìÔ∏è Processing leads for week: {start_date.date()} to {end_date.date()}\")\n",
    "    print(f\"Total leads in week: {len(weekly_leads)}\")\n",
    "    if len(weekly_leads) == 0:\n",
    "        print(\"‚ö†Ô∏è No leads found in the specified week. Check timestamp format or date range in ContactTypeChange.csv.\")\n",
    "        print(\"Available timestamp range:\", df_property_leads['At'].min(), \"to\", df_property_leads['At'].max())\n",
    "\n",
    "    routed_leads = []\n",
    "    weekly_assignments = defaultdict(set)\n",
    "    weekly_lead_caps = defaultdict(int)\n",
    "    MAX_LEADS_PER_WEEK = 49  # 7 leads/day * 7 days\n",
    "    HIGH_VOLUME_THRESHOLD = 2  # Leads per similar expired property per active property\n",
    "\n",
    "    for _, lead in weekly_leads.iterrows():\n",
    "        active_prop_tag = lead['Tags']\n",
    "        lead_contact = lead['Contact']\n",
    "        \n",
    "        if active_prop_tag in active_to_expired_map:\n",
    "            candidate_expired_props = active_to_expired_map[active_prop_tag]\n",
    "            num_candidates = len(candidate_expired_props)\n",
    "            \n",
    "            is_high_volume = (len(weekly_leads[weekly_leads['Tags'] == active_prop_tag]) / num_candidates) > HIGH_VOLUME_THRESHOLD if num_candidates > 0 else False\n",
    "            \n",
    "            if is_high_volume:\n",
    "                ranked_candidates = [tag for tag in candidate_expired_props if tag in ranking_df['Tag'].values]\n",
    "                ranked_candidates.sort(key=lambda tag: ranking_df.loc[ranking_df['Tag'] == tag, 'Overall_Rank'].iloc[0] if tag in ranking_df['Tag'].values else float('inf'))\n",
    "                unranked_candidates = [tag for tag in candidate_expired_props if tag not in ranking_df['Tag'].values]\n",
    "                ranked_candidates.extend(unranked_candidates)\n",
    "                \n",
    "                for assigned_tag in ranked_candidates:\n",
    "                    if lead_contact not in weekly_assignments[assigned_tag] and weekly_lead_caps[assigned_tag] < MAX_LEADS_PER_WEEK:\n",
    "                        routed_leads.append({\n",
    "                            'lead_contact': lead_contact,\n",
    "                            'original_active_property_tag': active_prop_tag,\n",
    "                            'routed_to_expired_property_tag': assigned_tag,\n",
    "                            'timestamp': lead['At']\n",
    "                        })\n",
    "                        weekly_assignments[assigned_tag].add(lead_contact)\n",
    "                        weekly_lead_caps[assigned_tag] += 1\n",
    "                        break\n",
    "            else:\n",
    "                for i, assigned_tag in enumerate(candidate_expired_props):\n",
    "                    if lead_contact not in weekly_assignments[assigned_tag] and weekly_lead_caps[assigned_tag] < MAX_LEADS_PER_WEEK:\n",
    "                        routed_leads.append({\n",
    "                            'lead_contact': lead_contact,\n",
    "                            'original_active_property_tag': active_prop_tag,\n",
    "                            'routed_to_expired_property_tag': assigned_tag,\n",
    "                            'timestamp': lead['At']\n",
    "                        })\n",
    "                        weekly_assignments[assigned_tag].add(lead_contact)\n",
    "                        weekly_lead_caps[assigned_tag] += 1\n",
    "                        break\n",
    "\n",
    "    if routed_leads:\n",
    "        routing_results_df = pd.DataFrame(routed_leads)\n",
    "        print(f\"\\n‚úÖ Lead routing complete. Created {len(routing_results_df)} new lead assignments.\")\n",
    "        generate_weekly_lead_report(ranking_df, routing_results_df, start_date.date(), end_date.date())\n",
    "    else:\n",
    "        print(\"\\n‚ÑπÔ∏è No new leads were routed for the matched properties.\")\n",
    "\n",
    "# --- How to run this ---\n",
    "# route_weekly_leads_prioritized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ec8845b-d713-432e-a4da-074a7fb5fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting weekly lead routing with dynamic priority queue logic...\n",
      "\n",
      "üîç Cleaning and filtering lead interaction tags...\n",
      "‚úÖ Found 80810 interactions linked to specific properties.\n",
      "Sample timestamps after parsing:\n",
      "                                        Tags                  At\n",
      "0     c-25-pritam-park-part-2-amriwadi-aug24 2024-08-21 12:55:00\n",
      "2                1-patelsociety-cgroad-aug24 2024-08-14 11:23:00\n",
      "3    7-jivaraj-nagar-society-shahibaug-sep24 2024-09-16 17:25:00\n",
      "4    7-jivaraj-nagar-society-shahibaug-sep24 2024-09-04 18:14:00\n",
      "5  110-elite-magnun-ghatlodia-com-rent-may24 2024-07-22 18:06:00\n",
      "Found 677 unique expired property tags (cleaned).\n",
      "Sample active-to-expired mappings (after cleaning tags):\n",
      "Active recalling: ['a-403-unique-lake-square-gota-jan24']\n",
      "Active 1-bhagirath-society-naranpura-feb25: ['22-vaibhav-laxmi-park-ghatlodia-sep24,', '16-shivam-bunglow-sola-oct24', '7-8-Giridhari-society-ranip-march25']\n",
      "Active 1-silver-stone-35-vavol-may25: ['3-silver-stone-35-vavol-may35', 'a-101-sagar-daynamic-sargasan-jan25', 'd-601-pramukh-horizon-2-sargasan-feb25']\n",
      "Active 1-status-elysium-gota-may25: ['105-rajvi-rivera-ranip-nov24', 'shop-111-rajvi-rivera-nava-vadaj-nov24', 'd-7-silver-pearl-ghatlodia-jan25']\n",
      "Active 1-vallabh-park-bopal-aug25: ['11-jal-vihar-bopal-feb25', '55-suryoday-bunglows-thaltej-nov24']\n",
      "Lead tags in ContactTypeChange.csv: 3651\n",
      "Active tags in active_to_expired_mapping.json (cleaned): 529\n",
      "Matching tags: 489\n",
      "Sample matching tags: ['a-4-krishna-tower-satellite-jul25', 'a-702-shree-hari-divine-zundal-may25', 'shop-22-shreeji-complex-paldi-jun25', 'e-502-samruddh-green-residency-vastral-jun25', '6-shiromani-bunglows-ctm-aug25']\n",
      "\n",
      "üìà Engineering features for property ranking...\n",
      "\n",
      "üóìÔ∏è Processing leads for week: 2025-08-17 to 2025-08-23\n",
      "Total leads in week: 2268\n",
      "\n",
      "‚úÖ Lead routing complete. Created 1315 new lead assignments.\n",
      "\n",
      "üìÑ Generating Weekly HTML Lead Report ---\n",
      "‚úÖ Weekly report saved to 'weekly_lead_report.html'.\n",
      "‚úÖ Routed leads saved to 'weekly_routed_leads.csv'.\n"
     ]
    }
   ],
   "source": [
    "route_weekly_leads_prioritized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e55c5d7-a791-4e2d-8eeb-33fea2972eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    total_properties_receiving_leads = len(lead_counts_per_property)\n",
    "    lead_distribution = lead_counts_per_property.value_counts().sort_index().reset_index()\n",
    "    lead_distribution.columns = ['Number of Leads Received', 'Number of Properties']\n",
    "\n",
    "    plot_base64 = generate_plot_base64(lead_distribution)\n",
    "\n",
    "    rank_map = ranking_df.set_index('Tag')['Overall_Rank'].to_dict()\n",
    "    grouped = routed_leads_df.groupby('routed_to_expired_property_tag')\n",
    "    html_parts = []\n",
    "    sorted_groups = sorted(grouped, key=lambda x: len(x[1].drop_duplicates(subset=['lead_contact'])), reverse=True)\n",
    "\n",
    "    for expired_tag, group_df in sorted_groups:\n",
    "        num_unique_leads = len(group_df.drop_duplicates(subset=['lead_contact']))\n",
    "        rank = rank_map.get(expired_tag, 'N/A')\n",
    "        details_header = f\"\"\"<details><summary><strong>Rank #{rank}: {expired_tag}</strong> &mdash; Received {num_unique_leads} Unique Leads</summary>\"\"\"\n",
    "        leads_table = group_df[['lead_contact', 'original_active_property_tag', 'timestamp']].to_html(index=False)\n",
    "        details_footer = \"</details>\"\n",
    "        html_parts.append(details_header + leads_table + details_footer)\n",
    "\n",
    "    final_html = f\"\"\"\n",
    "    <html><head><title>Weekly Lead Routing Report ({start_date} to {end_date})</title>\n",
    "    <style>\n",
    "        body {{ font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial, sans-serif; margin: 40px; color: #333; }}\n",
    "        h1, h2, h3 {{ color: #2c3e50; }}\n",
    "        .summary-box {{ background-color: #eaf2f8; border-left: 5px solid #3498db; padding: 15px; margin-bottom: 30px; }}\n",
    "        details {{ border: 1px solid #ddd; border-radius: 8px; margin-bottom: 10px; overflow: hidden; }}\n",
    "        summary {{ padding: 15px; font-size: 1.1em; font-weight: bold; background-color: #f7f7f7; cursor: pointer; outline: none; }}\n",
    "        table {{ width: 100%; border-collapse: collapse; }}\n",
    "        th, td {{ padding: 12px 15px; border-top: 1px solid #ddd; text-align: left; }}\n",
    "        th {{ background-color: #f2f2f2; }}\n",
    "        tr:nth-child(even) {{ background-color: #fafafa; }}\n",
    "        img {{ max-width: 100%; height: auto; margin-top: 20px; }}\n",
    "    </style>\n",
    "    </head><body>\n",
    "    <h1>Weekly Lead Routing Report ({start_date} to {end_date})</h1>\n",
    "    <h2>Summary Statistics</h2>\n",
    "    <div class=\"summary-box\">\n",
    "        <p><strong>Total Unique Leads Routed:</strong> {total_assignments}</p>\n",
    "        <p><strong>Total Expired Properties Receiving Leads:</strong> {total_properties_receiving_leads}</p>\n",
    "    </div>\n",
    "    <h3>Lead Distribution Breakdown</h3>\n",
    "    {lead_distribution.to_html(index=False)}\n",
    "    <h3>Lead Distribution Visualization</h3>\n",
    "    <img src=\"data:image/png;base64,{plot_base64}\" alt=\"Lead Distribution\">\n",
    "    <h2>Detailed Lead Log</h2>\n",
    "    <p>Click on each property to see the full list of leads it received.</p>\n",
    "    {''.join(html_parts)}\n",
    "    </body></html>\n",
    "    \"\"\"\n",
    "    \n",
    "    report_path = 'weekly_lead_report.html'\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(final_html)\n",
    "    print(f\"‚úÖ Weekly report saved to '{report_path}'.\")\n",
    "    routed_leads_df.to_csv('weekly_routed_leads.csv', index=False)\n",
    "    print(f\"‚úÖ Routed leads saved to 'weekly_routed_leads.csv'.\")\n",
    "\n",
    "def route_weekly_leads_prioritized():\n",
    "    \"\"\"\n",
    "    Routes leads for one week (Aug 17‚Äì23, 2025) using a dynamic priority queue model.\n",
    "    High lead volume: Prioritize high-ranked properties.\n",
    "    Low lead volume: Distribute evenly across similar expired properties.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting weekly lead routing with dynamic priority queue logic...\")\n",
    "    \n",
    "    try:\n",
    "        with open('active_to_expired_mapping.json', 'r') as f:\n",
    "            active_to_expired_matches = json.load(f)\n",
    "        df_changes = pd.read_csv('ContactTypeChange.csv', low_memory=False)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error: Missing a required file. {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nüîç Cleaning and filtering lead interaction tags...\")\n",
    "    df_changes['At'] = df_changes['At'].apply(parse_custom_date)\n",
    "    df_changes['tag_type'] = df_changes['Tags'].apply(categorize_tag)\n",
    "    df_property_leads = df_changes[df_changes['tag_type'] == 'property_identifier'].copy()\n",
    "    print(f\"‚úÖ Found {len(df_property_leads)} interactions linked to specific properties.\")\n",
    "    print(\"Sample timestamps after parsing:\")\n",
    "    print(df_property_leads[['Tags', 'At']].head())\n",
    "\n",
    "    all_expired_tags = set()\n",
    "    active_to_expired_map = defaultdict(list)\n",
    "    for active_tag, matches in active_to_expired_matches.items():\n",
    "        active_tag_clean = active_tag.split('_')[0]  # Remove _index suffix\n",
    "        for match in matches:\n",
    "            expired_tag = match['expired_tag']\n",
    "            expired_tag_clean = expired_tag.split('_')[0]  # Strip _index from expired tags\n",
    "            all_expired_tags.add(expired_tag_clean)\n",
    "            active_to_expired_map[active_tag_clean].append(expired_tag_clean)\n",
    "    print(f\"Found {len(all_expired_tags)} unique expired property tags (cleaned).\")\n",
    "    print(\"Sample active-to-expired mappings (after cleaning tags):\")\n",
    "    for active_tag in list(active_to_expired_map.keys())[:5]:\n",
    "        print(f\"Active {active_tag}: {active_to_expired_map[active_tag][:3]}\")\n",
    "\n",
    "    df_property_leads['Tags'] = df_property_leads['Tags'].apply(lambda tag: tag.split('_')[0] if '_' in str(tag) else tag)\n",
    "\n",
    "    lead_tags = set(df_property_leads['Tags'])\n",
    "    active_tags = set(active_to_expired_map.keys())\n",
    "    matching_tags = lead_tags.intersection(active_tags)\n",
    "    print(f\"Lead tags in ContactTypeChange.csv: {len(lead_tags)}\")\n",
    "    print(f\"Active tags in active_to_expired_mapping.json (cleaned): {len(active_tags)}\")\n",
    "    print(f\"Matching tags: {len(matching_tags)}\")\n",
    "    if matching_tags:\n",
    "        print(\"Sample matching tags:\", list(matching_tags)[:5])\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No matching tags found. Check tag formats in ContactTypeChange.csv and active_to_expired_mapping.json.\")\n",
    "\n",
    "    ranking_df = create_property_ranking(df_property_leads, all_expired_tags)\n",
    "    if ranking_df.empty:\n",
    "        print(\"‚ö†Ô∏è No ranking data available. Using default ranking for all expired properties.\")\n",
    "        ranking_df = pd.DataFrame({'Tag': list(all_expired_tags), 'Rank_Score': 0.5, 'Overall_Rank': range(1, len(all_expired_tags) + 1)})\n",
    "\n",
    "    start_date = pd.to_datetime('2025-08-17')\n",
    "    end_date = pd.to_datetime('2025-08-23')\n",
    "    weekly_leads = df_property_leads[(df_property_leads['At'].dt.date >= start_date.date()) & (df_property_leads['At'].dt.date <= end_date.date())]\n",
    "    print(f\"\\nüóìÔ∏è Processing leads for week: {start_date.date()} to {end_date.date()}\")\n",
    "    print(f\"Total leads in week: {len(weekly_leads)}\")\n",
    "    if len(weekly_leads) == 0:\n",
    "        print(\"‚ö†Ô∏è No leads found in the specified week. Check timestamp format or date range in ContactTypeChange.csv.\")\n",
    "        print(\"Available timestamp range:\", df_property_leads['At'].min(), \"to\", df_property_leads['At'].max())\n",
    "\n",
    "    routed_leads = []\n",
    "    weekly_assignments = defaultdict(set)\n",
    "    weekly_lead_caps = defaultdict(int)\n",
    "    MAX_LEADS_PER_WEEK = 49  # 7 leads/day * 7 days\n",
    "    HIGH_VOLUME_THRESHOLD = 2  # Leads per similar expired property per active property\n",
    "\n",
    "    for _, lead in weekly_leads.iterrows():\n",
    "        active_prop_tag = lead['Tags']\n",
    "        lead_contact = lead['Contact']\n",
    "        \n",
    "        if active_prop_tag in active_to_expired_map:\n",
    "            candidate_expired_props = [tag.split('_')[0] for tag in active_to_expired_map[active_prop_tag]]  # Clean tags here\n",
    "            num_candidates = len(candidate_expired_props)\n",
    "            \n",
    "            is_high_volume = (len(weekly_leads[weekly_leads['Tags'] == active_prop_tag]) / num_candidates) > HIGH_VOLUME_THRESHOLD if num_candidates > 0 else False\n",
    "            \n",
    "            if is_high_volume:\n",
    "                ranked_candidates = [tag for tag in candidate_expired_props if tag in ranking_df['Tag'].values]\n",
    "                ranked_candidates.sort(key=lambda tag: ranking_df.loc[ranking_df['Tag'] == tag, 'Overall_Rank'].iloc[0] if tag in ranking_df['Tag'].values else float('inf'))\n",
    "                unranked_candidates = [tag for tag in candidate_expired_props if tag not in ranking_df['Tag'].values]\n",
    "                ranked_candidates.extend(unranked_candidates)\n",
    "                \n",
    "                for assigned_tag in ranked_candidates:\n",
    "                    if lead_contact not in weekly_assignments[assigned_tag] and weekly_lead_caps[assigned_tag] < MAX_LEADS_PER_WEEK:\n",
    "                        routed_leads.append({\n",
    "                            'lead_contact': lead_contact,\n",
    "                            'original_active_property_tag': active_prop_tag,\n",
    "                            'routed_to_expired_property_tag': assigned_tag,\n",
    "                            'timestamp': lead['At']\n",
    "                        })\n",
    "                        weekly_assignments[assigned_tag].add(lead_contact)\n",
    "                        weekly_lead_caps[assigned_tag] += 1\n",
    "                        break\n",
    "            else:\n",
    "                for i, assigned_tag in enumerate(candidate_expired_props):\n",
    "                    if lead_contact not in weekly_assignments[assigned_tag] and weekly_lead_caps[assigned_tag] < MAX_LEADS_PER_WEEK:\n",
    "                        routed_leads.append({\n",
    "                            'lead_contact': lead_contact,\n",
    "                            'original_active_property_tag': active_prop_tag,\n",
    "                            'routed_to_expired_property_tag': assigned_tag,\n",
    "                            'timestamp': lead['At']\n",
    "                        })\n",
    "                        weekly_assignments[assigned_tag].add(lead_contact)\n",
    "                        weekly_lead_caps[assigned_tag] += 1\n",
    "                        break\n",
    "\n",
    "    if routed_leads:\n",
    "        routing_results_df = pd.DataFrame(routed_leads)\n",
    "        print(f\"\\n‚úÖ Lead routing complete. Created {len(routing_results_df)} new lead assignments.\")\n",
    "        generate_weekly_lead_report(ranking_df, routing_results_df, start_date.date(), end_date.date())\n",
    "    else:\n",
    "        print(\"\\n‚ÑπÔ∏è No new leads were routed for the matched properties.\")\n",
    "\n",
    "# --- How to run this ---\n",
    "# route_weekly_leads_prioritized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33deacd1-deb5-4fa8-b22a-6119905e79aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting weekly lead routing with dynamic priority queue logic...\n",
      "\n",
      "üîç Cleaning and filtering lead interaction tags...\n",
      "‚úÖ Found 80810 interactions linked to specific properties.\n",
      "Sample timestamps after parsing:\n",
      "                                        Tags                  At\n",
      "0     c-25-pritam-park-part-2-amriwadi-aug24 2024-08-21 12:55:00\n",
      "2                1-patelsociety-cgroad-aug24 2024-08-14 11:23:00\n",
      "3    7-jivaraj-nagar-society-shahibaug-sep24 2024-09-16 17:25:00\n",
      "4    7-jivaraj-nagar-society-shahibaug-sep24 2024-09-04 18:14:00\n",
      "5  110-elite-magnun-ghatlodia-com-rent-may24 2024-07-22 18:06:00\n",
      "Found 677 unique expired property tags (cleaned).\n",
      "Sample active-to-expired mappings (after cleaning tags):\n",
      "Active recalling: ['a-403-unique-lake-square-gota-jan24']\n",
      "Active 1-bhagirath-society-naranpura-feb25: ['22-vaibhav-laxmi-park-ghatlodia-sep24,', '16-shivam-bunglow-sola-oct24', '7-8-Giridhari-society-ranip-march25']\n",
      "Active 1-silver-stone-35-vavol-may25: ['3-silver-stone-35-vavol-may35', 'a-101-sagar-daynamic-sargasan-jan25', 'd-601-pramukh-horizon-2-sargasan-feb25']\n",
      "Active 1-status-elysium-gota-may25: ['105-rajvi-rivera-ranip-nov24', 'shop-111-rajvi-rivera-nava-vadaj-nov24', 'd-7-silver-pearl-ghatlodia-jan25']\n",
      "Active 1-vallabh-park-bopal-aug25: ['11-jal-vihar-bopal-feb25', '55-suryoday-bunglows-thaltej-nov24']\n",
      "Lead tags in ContactTypeChange.csv: 3651\n",
      "Active tags in active_to_expired_mapping.json (cleaned): 529\n",
      "Matching tags: 489\n",
      "Sample matching tags: ['a-4-krishna-tower-satellite-jul25', 'a-702-shree-hari-divine-zundal-may25', 'shop-22-shreeji-complex-paldi-jun25', 'e-502-samruddh-green-residency-vastral-jun25', '6-shiromani-bunglows-ctm-aug25']\n",
      "\n",
      "üìà Engineering features for property ranking...\n",
      "‚úÖ Ranking complete. Top 5 ranked properties:\n",
      "                                      Tag  Rank_Score  Overall_Rank\n",
      "0        a-304-vrajdham-1-ghatlodia-jan25    0.712929             1\n",
      "1  201-snehankit-society-aundh-pune-may25    0.659452             2\n",
      "2           c-203-ganesh-gold-gota-sept24    0.639406             3\n",
      "3     155-aarti-apartment-ghatlodia-feb25    0.613854             4\n",
      "4           a-13-tirthnagar-society-dec24    0.597460             5\n",
      "\n",
      "üóìÔ∏è Processing leads for week: 2025-08-17 to 2025-08-23\n",
      "Total leads in week: 2268\n",
      "\n",
      "‚úÖ Lead routing complete. Created 1315 new lead assignments.\n",
      "\n",
      "üìÑ Generating Weekly HTML Lead Report ---\n",
      "‚úÖ Weekly report saved to 'weekly_lead_report.html'.\n",
      "‚úÖ Routed leads saved to 'weekly_routed_leads.csv'.\n"
     ]
    }
   ],
   "source": [
    "route_weekly_leads_prioritized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e54993-6205-430f-9bc7-ba58369e5fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded 'ContactTypeChange-24.csv' (26688 rows), 'ContactTypeChange-25.csv' (57417 rows), and 'ContactTypeChange-August.csv' (6739 rows).\n",
      "‚úÖ Files combined successfully. Total rows: 90844.\n",
      "‚úÖ Combined data saved to 'ContactTypeChange.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def combine_three_csv_files(file1, file2, file3, output_file):\n",
    "    \"\"\"\n",
    "    Combines three CSV files into a single new CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Load all three CSV files into pandas DataFrames\n",
    "        df1 = pd.read_csv(file1, low_memory=False)\n",
    "        df2 = pd.read_csv(file2, low_memory=False)\n",
    "        df3 = pd.read_csv(file3, low_memory=False)\n",
    "        print(f\"‚úÖ Successfully loaded '{file1}' ({len(df1)} rows), '{file2}' ({len(df2)} rows), and '{file3}' ({len(df3)} rows).\")\n",
    "\n",
    "        # Step 2: Combine the three DataFrames into a single list\n",
    "        all_dfs = [df1, df2, df3]\n",
    "        \n",
    "        # Step 3: Concatenate the list of DataFrames\n",
    "        combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "        print(f\"‚úÖ Files combined successfully. Total rows: {len(combined_df)}.\")\n",
    "\n",
    "        # Step 4: Save the combined DataFrame to a new CSV file\n",
    "        combined_df.to_csv(output_file, index=False)\n",
    "        print(f\"‚úÖ Combined data saved to '{output_file}'.\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error: A required file was not found. {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# --- How to run this ---\n",
    "# Define the names of your three input files and the desired output file\n",
    "file_2024 = 'ContactTypeChange-24.csv'\n",
    "file_2025 = 'ContactTypeChange-25.csv'\n",
    "file_august = 'ContactTypeChange-August.csv' # Make sure to name your new file accordingly\n",
    "output_filename = 'ContactTypeChange.csv'\n",
    "\n",
    "# Call the function to perform the combination\n",
    "combine_three_csv_files(file_2024, file_2025, file_august, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fd3d4dd-1db2-4b69-b478-038128a35684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique leads routed in the week: 1122\n",
      "Unique leads routed on 2025-08-21: 110\n",
      "\n",
      "Columns in ContactTypeChange.csv: ['Contact', 'Phone1', 'Phone2', 'Email', 'Tags', 'Company', 'Source', 'City', 'State', 'Pincode', 'Country', 'From Lead Type', 'To Lead Type', 'Changed By', 'At']\n",
      "\n",
      "Total leads in the week (before filtering): 2515\n",
      "Total leads in the week (property_identifier only): 2268\n",
      "Unique leads in the week: 1812\n",
      "Unrouted unique leads in the week: 690\n",
      "\n",
      "Analyzing reasons for unrouted leads:\n",
      "\n",
      "Saved 32 unassigned leads to 'unassigned_leads.csv'.\n",
      "Top 5 unassigned leads:\n",
      "     lead_contact                               active_tag  \\\n",
      "0     Ajay Mahida     i-502-aashirwad-dreams-vastral-jul25   \n",
      "1    AmrutaRajput  a-104-nar-narayan-apartment-nikol-jul25   \n",
      "2      Anil Kumar    103-stela-apex-pimpri-chinchwad-jul25   \n",
      "3      BaljitKaur        a-304-shiv-residency-chhani-aug25   \n",
      "4  Christian Keny             a-5-tulsi-bunglows-ctm-jun25   \n",
      "\n",
      "            timestamp                                             reason  \n",
      "0 2025-08-18 16:28:00  No eligible expired property (capped or alread...  \n",
      "1 2025-08-18 12:53:00  No eligible expired property (capped or alread...  \n",
      "2 2025-08-19 10:41:00  No eligible expired property (capped or alread...  \n",
      "3 2025-08-19 11:40:00  No eligible expired property (capped or alread...  \n",
      "4 2025-08-18 10:53:00  No eligible expired property (capped or alread...  \n",
      "\n",
      "Top 5 active tags with unassigned leads:\n",
      "active_tag\n",
      "a-1-shree-ambica-duplex-naroda-may25         7\n",
      "e-202-garden-paradise-bopal-aug25            3\n",
      "303-sulabh-exotica-maninagar-aug25           2\n",
      "a-601-empire-heights-ghodasar-jul25          2\n",
      "d-206-swapna-sakar-residency-lambha-jul25    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Reasons for unassigned leads:\n",
      "reason\n",
      "No eligible expired property (capped or already assigned)    32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Active properties without leads in the week: 320 out of 719 active properties.\n",
      "Active properties with leads but no matching expired property: 131\n",
      "\n",
      "Expired properties that hit the lead cap (49): 2\n",
      "Sample cap-limited expired tags: ['d-304-samyak-galaxy-gota-feb25', '34-jay-barjarng-society-bapunagar-jan24']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "# Helper function to parse custom dates\n",
    "def parse_custom_date(date_str):\n",
    "    if pd.isna(date_str): return pd.NaT\n",
    "    try:\n",
    "        date_str = re.sub(r'(\\d+)(st|nd|rd|th)', r'\\1', date_str)\n",
    "        return pd.to_datetime(date_str, format='%b %d %Y, %I:%M %p', errors='coerce')\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "# Helper function to categorize tags\n",
    "def categorize_tag(tag):\n",
    "    if pd.isna(tag): return 'unknown'\n",
    "    tag_str = str(tag).lower().strip()\n",
    "    if re.match(r'^\\d{2}-[a-z]{3}-\\d{2}-(99acres|magicbricks|olx|housing)', tag_str): return 'date_source_combo'\n",
    "    if re.match(r'^\\d{2}-\\d{2}-\\d{4}$', tag_str): return 'date_only'\n",
    "    if tag_str in ['sell-leads', 'cleardeals-lead', 'lead', 'recalling']: return 'generic_status'\n",
    "    if re.search(r'\\d', tag_str) and re.search(r'[a-zA-Z]', tag_str) and '-' in tag_str: return 'property_identifier'\n",
    "    return 'other'\n",
    "\n",
    "# Load routed leads\n",
    "try:\n",
    "    routed_leads_df = pd.read_csv('weekly_routed_leads.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'weekly_routed_leads.csv' not found.\")\n",
    "    exit()\n",
    "\n",
    "# 1. Unique leads routed (week and specific day)\n",
    "unique_leads_routed = routed_leads_df['lead_contact'].nunique()\n",
    "print(f\"Unique leads routed in the week: {unique_leads_routed}\")\n",
    "\n",
    "specific_day = '2025-08-21'  # Adjusted to 2024\n",
    "routed_leads_df['timestamp'] = pd.to_datetime(routed_leads_df['timestamp'])\n",
    "daily_routed = routed_leads_df[routed_leads_df['timestamp'].dt.date == pd.to_datetime(specific_day).date()]\n",
    "unique_leads_routed_day = daily_routed['lead_contact'].nunique()\n",
    "print(f\"Unique leads routed on {specific_day}: {unique_leads_routed_day}\")\n",
    "\n",
    "# Load all leads\n",
    "try:\n",
    "    df_changes = pd.read_csv('ContactTypeChange.csv', low_memory=False)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'ContactTypeChange.csv' not found.\")\n",
    "    exit()\n",
    "\n",
    "# Verify column names\n",
    "expected_columns = ['Tags', 'Contact', 'At']\n",
    "actual_columns = df_changes.columns.tolist()\n",
    "print(f\"\\nColumns in ContactTypeChange.csv: {actual_columns}\")\n",
    "for col in expected_columns:\n",
    "    if col not in actual_columns:\n",
    "        print(f\"Error: Expected column '{col}' not found. Update script with correct column names.\")\n",
    "        exit()\n",
    "\n",
    "# Parse timestamps and categorize tags\n",
    "df_changes['At'] = df_changes['At'].apply(parse_custom_date)\n",
    "df_changes['tag_type'] = df_changes['Tags'].apply(categorize_tag)\n",
    "\n",
    "# Filter for the week\n",
    "start_date = pd.to_datetime('2025-08-17')\n",
    "end_date = pd.to_datetime('2025-08-23')\n",
    "weekly_leads = df_changes[(df_changes['At'].dt.date >= start_date.date()) & (df_changes['At'].dt.date <= end_date.date())]\n",
    "print(f\"\\nTotal leads in the week (before filtering): {len(weekly_leads)}\")\n",
    "\n",
    "# Filter for property_identifier tags\n",
    "weekly_leads = weekly_leads[weekly_leads['tag_type'] == 'property_identifier']\n",
    "print(f\"Total leads in the week (property_identifier only): {len(weekly_leads)}\")\n",
    "\n",
    "# 2. Unrouted unique leads\n",
    "all_unique_leads = weekly_leads['Contact'].nunique()\n",
    "print(f\"Unique leads in the week: {all_unique_leads}\")\n",
    "unrouted_unique_leads = all_unique_leads - unique_leads_routed\n",
    "print(f\"Unrouted unique leads in the week: {unrouted_unique_leads}\")\n",
    "if unrouted_unique_leads < 0:\n",
    "    print(\"Warning: Negative unrouted leads. Possible data mismatch in ContactTypeChange.csv or weekly_routed_leads.csv.\")\n",
    "\n",
    "# 3. Reasons for unrouted leads\n",
    "print(\"\\nAnalyzing reasons for unrouted leads:\")\n",
    "# Load active-to-expired mappings\n",
    "try:\n",
    "    with open('active_to_expired_mapping.json', 'r') as f:\n",
    "        active_to_expired = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'active_to_expired_mapping.json' not found.\")\n",
    "    exit()\n",
    "\n",
    "# Clean active and expired tags\n",
    "active_tags = set(active_tag.split('_')[0] for active_tag in active_to_expired.keys())\n",
    "active_to_expired_map = defaultdict(list)\n",
    "for active_tag, matches in active_to_expired.items():\n",
    "    active_tag_clean = active_tag.split('_')[0]\n",
    "    for match in matches:\n",
    "        expired_tag_clean = match['expired_tag'].split('_')[0]\n",
    "        active_to_expired_map[active_tag_clean].append(expired_tag_clean)\n",
    "\n",
    "# Active properties with leads\n",
    "active_with_leads = set(weekly_leads['Tags'].apply(lambda tag: tag.split('_')[0] if '_' in str(tag) else tag))\n",
    "\n",
    "# Simulate routing to identify unassigned leads\n",
    "unassigned_leads = []\n",
    "weekly_assignments = defaultdict(set)\n",
    "weekly_lead_caps = defaultdict(int)\n",
    "MAX_LEADS_PER_WEEK = 49  # Match original routing\n",
    "HIGH_VOLUME_THRESHOLD = 2\n",
    "\n",
    "for _, lead in weekly_leads.iterrows():\n",
    "    active_prop_tag = lead['Tags'].split('_')[0] if '_' in str(lead['Tags']) else lead['Tags']\n",
    "    lead_contact = lead['Contact']\n",
    "    if active_prop_tag in active_to_expired_map:\n",
    "        candidate_expired_props = active_to_expired_map[active_prop_tag]\n",
    "        num_candidates = len(candidate_expired_props)\n",
    "        is_high_volume = (len(weekly_leads[weekly_leads['Tags'].apply(lambda x: x.split('_')[0] if '_' in str(x) else x) == active_prop_tag]) / num_candidates) > HIGH_VOLUME_THRESHOLD if num_candidates > 0 else False\n",
    "        assigned = False\n",
    "        if is_high_volume:\n",
    "            for assigned_tag in candidate_expired_props:\n",
    "                if lead_contact not in weekly_assignments[assigned_tag] and weekly_lead_caps[assigned_tag] < MAX_LEADS_PER_WEEK:\n",
    "                    weekly_assignments[assigned_tag].add(lead_contact)\n",
    "                    weekly_lead_caps[assigned_tag] += 1\n",
    "                    assigned = True\n",
    "                    break\n",
    "        else:\n",
    "            for assigned_tag in candidate_expired_props:\n",
    "                if lead_contact not in weekly_assignments[assigned_tag] and weekly_lead_caps[assigned_tag] < MAX_LEADS_PER_WEEK:\n",
    "                    weekly_assignments[assigned_tag].add(lead_contact)\n",
    "                    weekly_lead_caps[assigned_tag] += 1\n",
    "                    assigned = True\n",
    "                    break\n",
    "        if not assigned:\n",
    "            unassigned_leads.append({\n",
    "                'lead_contact': lead_contact,\n",
    "                'active_tag': active_prop_tag,\n",
    "                'timestamp': lead['At'],\n",
    "                'reason': 'No eligible expired property (capped or already assigned)' if candidate_expired_props else 'No matching expired properties'\n",
    "            })\n",
    "\n",
    "# Save unassigned leads\n",
    "if unassigned_leads:\n",
    "    unassigned_df = pd.DataFrame(unassigned_leads)\n",
    "    unassigned_df.to_csv('unassigned_leads.csv', index=False)\n",
    "    print(f\"\\nSaved {len(unassigned_leads)} unassigned leads to 'unassigned_leads.csv'.\")\n",
    "    print(\"Top 5 unassigned leads:\")\n",
    "    print(unassigned_df.head())\n",
    "    print(\"\\nTop 5 active tags with unassigned leads:\")\n",
    "    print(unassigned_df['active_tag'].value_counts().head())\n",
    "    print(\"\\nReasons for unassigned leads:\")\n",
    "    print(unassigned_df['reason'].value_counts())\n",
    "\n",
    "# 4. Active properties without leads\n",
    "active_without_leads = len(active_tags - active_with_leads)\n",
    "print(f\"\\nActive properties without leads in the week: {active_without_leads} out of {len(active_tags)} active properties.\")\n",
    "\n",
    "# 5. Active properties with leads but no matching expired property\n",
    "active_with_leads_no_expired = len(active_with_leads - active_tags)\n",
    "print(f\"Active properties with leads but no matching expired property: {active_with_leads_no_expired}\")\n",
    "\n",
    "# 6. Cap-limited properties\n",
    "cap_limited = {tag: count for tag, count in weekly_lead_caps.items() if count >= MAX_LEADS_PER_WEEK}\n",
    "print(f\"\\nExpired properties that hit the lead cap ({MAX_LEADS_PER_WEEK}): {len(cap_limited)}\")\n",
    "if cap_limited:\n",
    "    print(\"Sample cap-limited expired tags:\", list(cap_limited.keys())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ef9c1-c470-42af-bf53-df72616f72cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07463586-f897-4c9e-8a7e-4e91cd8d1868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Lead Distribution Visualization...\n",
      "Lead Distribution Data:\n",
      "    Number of Leads Received  Number of Properties\n",
      "0                          1                    97\n",
      "1                          2                    39\n",
      "2                          3                    22\n",
      "3                          4                    16\n",
      "4                          5                    17\n",
      "5                          6                     5\n",
      "6                          7                    11\n",
      "7                          8                     6\n",
      "8                          9                     8\n",
      "9                         10                     6\n",
      "10                        11                     3\n",
      "11                        12                     2\n",
      "12                        13                     8\n",
      "13                        14                     3\n",
      "14                        15                     1\n",
      "15                        16                     3\n",
      "16                        17                     2\n",
      "17                        18                     3\n",
      "18                        19                     3\n",
      "19                        20                     1\n",
      "20                        22                     1\n",
      "21                        24                     1\n",
      "22                        26                     1\n",
      "23                        37                     1\n",
      "24                        49                     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_16188\\3446908612.py:36: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Number of Leads Received', y='Number of Properties', data=lead_distribution, palette='Blues_d')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to 'lead_distribution.png'.\n",
      "Saved updated HTML report to 'lead_distribution_report.html'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "def generate_lead_distribution_plot(routed_leads_df, output_png='lead_distribution.png', return_base64=True):\n",
    "    \"\"\"\n",
    "    Generates a lead distribution bar chart and saves it as a PNG.\n",
    "    Optionally returns a base64-encoded string for HTML embedding.\n",
    "    \"\"\"\n",
    "    print(\"\\nGenerating Lead Distribution Visualization...\")\n",
    "\n",
    "    # Verify routed_leads_df\n",
    "    if routed_leads_df.empty:\n",
    "        print(\"Error: routed_leads_df is empty. Cannot generate plot.\")\n",
    "        return None if return_base64 else None\n",
    "\n",
    "    # Calculate lead distribution\n",
    "    lead_counts_per_property = routed_leads_df.groupby('routed_to_expired_property_tag')['lead_contact'].nunique()\n",
    "    lead_distribution = lead_counts_per_property.value_counts().sort_index().reset_index()\n",
    "    lead_distribution.columns = ['Number of Leads Received', 'Number of Properties']\n",
    "    \n",
    "    print(\"Lead Distribution Data:\")\n",
    "    print(lead_distribution)\n",
    "\n",
    "    if lead_distribution.empty:\n",
    "        print(\"Error: lead_distribution is empty. Check routed_leads_df data.\")\n",
    "        return None if return_base64 else None\n",
    "\n",
    "    # Set plot style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Number of Leads Received', y='Number of Properties', data=lead_distribution, palette='Blues_d')\n",
    "    plt.title('Lead Distribution Across Expired Properties', fontsize=14, pad=15)\n",
    "    plt.xlabel('Number of Leads Received', fontsize=12)\n",
    "    plt.ylabel('Number of Properties', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot as PNG\n",
    "    plt.savefig(output_png, format='png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved plot to '{output_png}'.\")\n",
    "\n",
    "    # Generate base64 string if needed\n",
    "    if return_base64:\n",
    "        buffer = BytesIO()\n",
    "        plt.savefig(buffer, format='png', dpi=300, bbox_inches='tight')\n",
    "        buffer.seek(0)\n",
    "        plot_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "        plt.close()\n",
    "        return plot_base64\n",
    "    \n",
    "    plt.close()\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    # Load routed leads\n",
    "    try:\n",
    "        routed_leads_df = pd.read_csv('weekly_routed_leads.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: 'weekly_routed_leads.csv' not found.\")\n",
    "        return\n",
    "\n",
    "    # Generate and save plot\n",
    "    plot_base64 = generate_lead_distribution_plot(routed_leads_df, output_png='lead_distribution.png', return_base64=True)\n",
    "    \n",
    "    if plot_base64:\n",
    "        # Update HTML report with new plot\n",
    "        html_content = f\"\"\"\n",
    "        <html>\n",
    "        <head><title>Lead Distribution Visualization</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; margin: 40px; }}\n",
    "            h1 {{ color: #2c3e50; }}\n",
    "            img {{ max-width: 100%; height: auto; }}\n",
    "        </style>\n",
    "        </head>\n",
    "        <body>\n",
    "        <h1>Lead Distribution Across Expired Properties</h1>\n",
    "        <img src=\"data:image/png;base64,{plot_base64}\" alt=\"Lead Distribution\">\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        with open('lead_distribution_report.html', 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "        print(\"Saved updated HTML report to 'lead_distribution_report.html'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a7c7d-64ae-4081-b62f-78f9d694e1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
